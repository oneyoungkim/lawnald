# pyright: reportGeneralTypeIssues=false, reportMissingImports=false, reportOptionalMemberAccess=false, reportOptionalSubscript=false, reportOptionalCall=false, reportArgumentType=false, reportIndexIssue=false, reportOperatorIssue=false, reportCallIssue=false, reportReturnType=false, reportAttributeAccessIssue=false, reportMissingModuleSource=false
# pyre-ignore-all-errors
import os
import sys

# Vercel serverless: ensure api/ directory is in Python path
API_DIR = os.path.dirname(os.path.abspath(__file__))
if API_DIR not in sys.path:
    sys.path.insert(0, API_DIR)

from dotenv import load_dotenv  # type: ignore
load_dotenv(os.path.join(API_DIR, '.env'))

from fastapi import FastAPI, Query, UploadFile, File, HTTPException, Form, Body  # type: ignore
from pydantic import BaseModel  # type: ignore
from typing import List, Optional, Dict, Any
from fastapi.middleware.cors import CORSMiddleware  # type: ignore
# StaticFiles removed for Vercel serverless
from search import search_engine  # type: ignore
from data import LAWYERS_DB, save_lawyers_db  # type: ignore
import image_utils  # type: ignore
import os
import json
import seo   # type: ignore
import seo_helper   # type: ignore
from compliance import compliance_engine  # type: ignore
import consultation  # type: ignore
import hashlib 

from datetime import datetime, timedelta
from uuid import uuid4

app = FastAPI()

# Add CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Visitor Tracking (In-Memory) ---
from datetime import datetime, timedelta
from starlette.middleware.base import BaseHTTPMiddleware  # type: ignore
from starlette.requests import Request as StarletteRequest  # type: ignore
import time

# --- Supabase-Persistent Daily Stats ---

def _get_stats_sb():
    """Supabase í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    try:
        from supabase_client import get_supabase  # type: ignore
        return get_supabase()
    except Exception:
        return None

def _load_stats_from_supabase(date_str: str) -> dict:
    """Supabaseì—ì„œ íŠ¹ì • ë‚ ì§œì˜ í†µê³„ ë¡œë“œ"""
    sb = _get_stats_sb()
    if sb is None:
        return {}
    try:
        res = sb.table("site_stats").select("*").eq("date", date_str).execute()
        if res.data and len(res.data) > 0:
            row = res.data[0]
            return {
                "visitors": row.get("visitors", 0),
                "unique_ips_list": row.get("unique_ips", []),
                "page_views": row.get("page_views", 0),
                "avg_duration_ms": row.get("avg_duration_ms", 0),
            }
    except Exception as e:
        print(f"âš ï¸ Supabase í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return {}

def _load_all_stats_dates() -> list:
    """Supabaseì—ì„œ í†µê³„ê°€ ìˆëŠ” ë‚ ì§œ ëª©ë¡ ë¡œë“œ"""
    sb = _get_stats_sb()
    if sb is None:
        return []
    try:
        res = sb.table("site_stats").select("date").order("date", desc=True).limit(30).execute()
        return [r["date"] for r in (res.data or [])]
    except Exception:
        return []

def _flush_today_to_supabase():
    """ì˜¤ëŠ˜ í†µê³„ë¥¼ Supabaseì— ì €ì¥ (upsert)"""
    sb = _get_stats_sb()
    if sb is None:
        return

    today = _visitor_data["last_reset"]
    unique_ips_list = list(_visitor_data["unique_ips"])
    page_views = _visitor_data["page_views"]
    times = _visitor_data["request_times"]
    avg_ms = (sum(times) / len(times)) if times else 0  # type: ignore

    try:
        # ê¸°ì¡´ ë°ì´í„° ë³‘í•© â€” ì—¬ëŸ¬ ì„œë²„ë¦¬ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ê°€ ë™ì‹œì— ê¸°ë¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
        existing = _load_stats_from_supabase(today)
        existing_ips = set(existing.get("unique_ips_list", []))
        merged_ips = existing_ips | set(unique_ips_list)

        # page_views: ê¸°ì¡´ ê°’ê³¼ í˜„ì¬ ê°’ ì¤‘ í° ê°’ ì‚¬ìš© (ë®ì–´ì“°ê¸° ë°©ì§€)
        merged_pv = max(existing.get("page_views", 0), page_views)

        sb.table("site_stats").upsert({
            "date": today,
            "visitors": len(merged_ips),
            "page_views": merged_pv,
            "unique_ips": list(merged_ips),
            "avg_duration_ms": round(avg_ms, 1),
            "updated_at": datetime.now().isoformat(),
        }, on_conflict="date").execute()
    except Exception as e:
        print(f"âš ï¸ Supabase í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")

# Restore today's data from Supabase on startup
_today_str = datetime.now().strftime("%Y-%m-%d")
_saved = _load_stats_from_supabase(_today_str)

_visitor_data = {
    "unique_ips": set(_saved.get("unique_ips_list", [])),
    "page_views": _saved.get("page_views", 0),  # type: ignore
    "request_times": [],
    "last_reset": _today_str,
}
print(f"ğŸ“Š í†µê³„ ë³µì› (Supabase): {_today_str} â€” ë°©ë¬¸ì {len(_visitor_data['unique_ips'])}ëª…, í˜ì´ì§€ë·° {_visitor_data['page_views']}íšŒ")

_flush_counter = 0

def _reset_if_new_day():
    global _flush_counter
    today = datetime.now().strftime("%Y-%m-%d")
    if _visitor_data["last_reset"] != today:
        _flush_today_to_supabase()
        _visitor_data["unique_ips"] = set()
        _visitor_data["page_views"] = 0
        _visitor_data["request_times"] = []
        _visitor_data["last_reset"] = today
        _flush_counter = 0

class VisitorTrackingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: StarletteRequest, call_next):
        global _flush_counter
        _reset_if_new_day()
        start = time.time()
        
        client_ip = request.headers.get("x-forwarded-for", request.client.host if request.client else "unknown")
        if client_ip and "," in client_ip:
            client_ip = client_ip.split(",")[0].strip()
        
        path = request.url.path
        if not path.startswith("/_next") and path != "/favicon.ico":
            _visitor_data["unique_ips"].add(client_ip)  # type: ignore
            _visitor_data["page_views"] += 1  # type: ignore
        
        response = await call_next(request)
        
        duration = (time.time() - start) * 1000
        if not path.startswith("/_next") and path != "/favicon.ico":
            _visitor_data["request_times"].append(duration)  # type: ignore
            if len(_visitor_data["request_times"]) > 1000:
                _visitor_data["request_times"] = _visitor_data["request_times"][-500:]  # type: ignore
        
        _flush_counter += 1  # type: ignore
        if _flush_counter >= 20:
            _flush_today_to_supabase()
            _flush_counter = 0
        
        return response

app.add_middleware(VisitorTrackingMiddleware)

# --- Admin Stats Endpoints ---

@app.get("/api/admin/stats")
def get_admin_stats(date: Optional[str] = None):
    """ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ í†µê³„ (ì¼ë³„)"""
    _reset_if_new_day()
    _flush_today_to_supabase()
    
    today_str = datetime.now().strftime("%Y-%m-%d")
    query_date = date or today_str
    is_today = (query_date == today_str)
    
    available_dates = _load_all_stats_dates()
    
    if is_today:
        visitors = len(_visitor_data["unique_ips"])
        page_views = _visitor_data["page_views"]
        times = _visitor_data["request_times"]
    else:
        day_data = _load_stats_from_supabase(query_date)
        visitors = day_data.get("visitors", 0)  # type: ignore
        page_views = day_data.get("page_views", 0)  # type: ignore
        avg_saved = day_data.get("avg_duration_ms", 0)  # type: ignore
        times = [avg_saved] if avg_saved else []
    
    # Average duration
    if times and len(times) > 0:
        avg_ms = sum(times) / len(times)  # type: ignore
        if avg_ms > 60000:
            avg_duration = f"{avg_ms / 60000:.1f}ë¶„"
        elif avg_ms > 1000:
            avg_duration = f"{avg_ms / 1000:.1f}ì´ˆ"
        else:
            avg_duration = f"{avg_ms:.0f}ms"
    else:
        avg_duration = "â€”"
    
    today_consultations = 0
    try:
        today_consultations = len(chat_manager.active_rooms) if is_today and hasattr(chat_manager, 'active_rooms') else 0
    except Exception:
        pass
    
    return {
        "date": query_date,
        "visitors": visitors,
        "page_views": page_views,
        "avg_duration": avg_duration,
        "today_consultations": today_consultations,
        "available_dates": available_dates[:30],  # type: ignore
    }

@app.get("/api/admin/stats/dates")
def get_stats_dates():
    dates = _load_all_stats_dates()
    return {"dates": dates}

@app.get("/api/admin/crawler/today-count")
def get_crawler_today_count():
    """ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ì ì¬ íŒŒíŠ¸ë„ˆ ìˆ˜"""
    try:
        from lawyer_crawler import POTENTIAL_PARTNERS  # type: ignore
        today = datetime.now().strftime("%Y-%m-%d")
        today_count = len([p for p in POTENTIAL_PARTNERS if p.get("collected_at", "").startswith(today)])
        return {"today_count": today_count, "total": len(POTENTIAL_PARTNERS)}
    except (ImportError, Exception):
        return {"today_count": 0, "total": 0}


# --- WebSocket Setup (Declared early) ---
from chat import chat_manager  # type: ignore
from fastapi import WebSocket, WebSocketDisconnect  # type: ignore

@app.websocket("/ws/chat/{lawyer_id}/{client_id}/{role}")
async def websocket_endpoint(websocket: WebSocket, lawyer_id: str, client_id: str, role: str):
    # This endpoint on 8000 might not work due to environment issues, 
    # but we keep it for reference. Real chat should use port 8001.
    await chat_manager.connect(websocket, lawyer_id, client_id, role)
    try:
        while True:
            data = await websocket.receive_text()
            await chat_manager.send_message(lawyer_id, client_id, role, data)
    except WebSocketDisconnect:
        chat_manager.disconnect(lawyer_id, client_id, role)

@app.get("/api/chats/{lawyer_id}/{client_id}/messages")
async def get_chat_history(lawyer_id: str, client_id: str):
    return chat_manager.get_history(lawyer_id, client_id)

@app.get("/api/lawyers/{lawyer_id}/chats")
async def get_lawyer_chats(lawyer_id: str):
    return chat_manager.get_lawyer_chats(lawyer_id)

from routers.crawler import parse_naver_blog_url, get_blog_text, rewrite_with_llm, generate_cover_image  # type: ignore
# NOTE: crawler.router NOT included to avoid stale async endpoint conflict

# ë¸”ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° ì—”ë“œí¬ì¸íŠ¸
class BlogImportRequest(BaseModel):
    url: str

@app.post("/api/blog/import")
def blog_import_endpoint(request: BlogImportRequest):
    import traceback as tb
    try:
        blog_id, log_no = parse_naver_blog_url(request.url)
        if not blog_id or not log_no:
            from fastapi.responses import JSONResponse  # type: ignore
            return JSONResponse(status_code=400, content={"detail": "ì˜ëª»ëœ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URL í˜•ì‹ì…ë‹ˆë‹¤. ê°œë³„ í¬ìŠ¤íŠ¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})
        
        # â”€â”€ ì¤‘ë³µ URL ì²´í¬ (ë¹„ìš© ë‚­ë¹„ ë°©ì§€: LLM/DALL-E í˜¸ì¶œ ì „ì— í™•ì¸) â”€â”€
        canonical_url = f"https://blog.naver.com/{blog_id}/{log_no}"
        for lawyer in LAWYERS_DB:
            for item in lawyer.get("content_items", []):
                existing_url = item.get("original_url", "")
                if existing_url and (canonical_url in existing_url or existing_url in canonical_url or existing_url == request.url):
                    from fastapi.responses import JSONResponse  # type: ignore
                    return JSONResponse(status_code=409, content={"detail": f"ì´ë¯¸ ë“±ë¡ëœ ë¸”ë¡œê·¸ ê¸€ì…ë‹ˆë‹¤. (ë“±ë¡ì¼: {item.get('date', 'ì•Œ ìˆ˜ ì—†ìŒ')})"})
        
        print(f"[BlogImport] Crawling: {blog_id}/{log_no}")
        original_title, original_text = get_blog_text(blog_id, log_no)
        
        if not original_text or len(original_text.strip()) < 50:
            from fastapi.responses import JSONResponse  # type: ignore
            return JSONResponse(status_code=400, content={"detail": "ë¸”ë¡œê·¸ ê¸€ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹„ê³µê°œ ê¸€ì´ê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤."})
        
        print(f"[BlogImport] Got {len(original_text)} chars. LLM rewriting with SEO...")
        llm_result = rewrite_with_llm(original_text)
        
        print(f"[BlogImport] LLM done. Generating illustration image...")
        content_for_image = llm_result.get("content", "")[:1000]
        cover_image = generate_cover_image(content_for_image)
        
        # Embed generated image into content body (replace [IMAGE] placeholder)
        content = llm_result.get("content", original_text)
        if "[IMAGE]" in content:
            image_md = f"\n\n![ê´€ë ¨ ì‚½í™”]({cover_image})\n\n"
            content = content.replace("[IMAGE]", image_md, 1)
            print(f"[BlogImport] âœ… Image embedded into content body")
        else:
            # If LLM didn't place [IMAGE], insert after the first heading
            import re
            heading_match = re.search(r'(^##?\s+.+$)', content, re.MULTILINE)
            if heading_match:
                insert_pos = heading_match.end()
                # Find the next paragraph break
                next_para = content.find('\n\n', insert_pos)
                if next_para != -1:
                    image_md = f"\n\n![ê´€ë ¨ ì‚½í™”]({cover_image})\n\n"
                    content = content[:next_para] + image_md + content[next_para:]
                    print(f"[BlogImport] âœ… Image inserted after first section")
        
        print(f"[BlogImport] âœ… Complete! (SEO title: {llm_result.get('title', '')[:40]}...)")
        return {
            "title": llm_result.get("title", original_title),
            "content": content,
            "category": llm_result.get("category", "ê¸°íƒ€"),
            "keyword": llm_result.get("keyword", ""),
            "cover_image_url": cover_image,
            "original_url": request.url,
            "meta_description": llm_result.get("meta_description", ""),
            "slug": llm_result.get("slug", "")
        }
    except Exception as e:
        print(f"[BlogImport] âŒ ERROR: {e}")
        tb.print_exc()
        from fastapi.responses import JSONResponse  # type: ignore
        return JSONResponse(status_code=500, content={"detail": f"ë¸”ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}"})

# â”€â”€ ì˜¨ë””ë§¨ë“œ AI ì¸ë„¤ì¼ ìƒì„± (ë³€í˜¸ì‚¬ê°€ ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ í˜¸ì¶œ) â”€â”€
class ThumbnailRequest(BaseModel):
    content: str  # ê¸€ ë³¸ë¬¸ (í…Œë§ˆ ì¶”ì¶œìš©)

@app.post("/api/generate-thumbnail")
def generate_thumbnail_endpoint(request: ThumbnailRequest):
    """ë³€í˜¸ì‚¬ê°€ [âœ¨ AI ì¸ë„¤ì¼ ìƒì„±í•˜ê¸°] ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œë§Œ í˜¸ì¶œë©ë‹ˆë‹¤."""
    try:
        if not request.content or len(request.content.strip()) < 30:
            from fastapi.responses import JSONResponse  # type: ignore
            return JSONResponse(status_code=400, content={"detail": "ì¸ë„¤ì¼ ìƒì„±ì„ ìœ„í•´ ìµœì†Œ 30ì ì´ìƒì˜ ë³¸ë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤."})
        
        print(f"[Thumbnail] ğŸ¨ Generating on-demand thumbnail ({len(request.content)} chars)...")
        image_url = generate_cover_image(request.content[:1000])  # type: ignore
        print(f"[Thumbnail] âœ… Done: {image_url}")
        
        return {"image_url": image_url}
    except Exception as e:
        print(f"[Thumbnail] âŒ ERROR: {e}")
        from fastapi.responses import JSONResponse  # type: ignore
        return JSONResponse(status_code=500, content={"detail": f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}"})

try:
    from billing import router as billing_router  # type: ignore
    app.include_router(billing_router)
except Exception as e:
    print(f"âš ï¸ billing router skipped: {e}")

try:
    from admin_blog import router as admin_blog_router  # type: ignore
    app.include_router(admin_blog_router)
except Exception as e:
    print(f"âš ï¸ admin_blog router skipped: {e}")

try:
    from push_notifications import router as push_router  # type: ignore
    app.include_router(push_router)
except Exception as e:
    print(f"âš ï¸ push_notifications router skipped: {e}")

try:
    from document_generator import router as docgen_router  # type: ignore
    app.include_router(docgen_router)
except Exception as e:
    print(f"âš ï¸ document_generator router skipped: {e}")

try:
    from evidence_processor import router as evidence_router  # type: ignore
    app.include_router(evidence_router)
except Exception as e:
    print(f"âš ï¸ evidence_processor router skipped: {e}")

try:
    from case_workspace import router as workspace_router  # type: ignore
    app.include_router(workspace_router)
except Exception as e:
    print(f"âš ï¸ case_workspace router skipped: {e}")

print("\n" + "="*50)
print("STARTUP: Main.py loaded successfully")
print("="*50 + "\n")






# Vercel serverless: use /tmp for writable directory
try:
    os.makedirs("/tmp/uploads", exist_ok=True)
    os.makedirs("/tmp/temp_uploads", exist_ok=True)
except:
    pass

print(f"Serverless function loaded. CWD={os.getcwd()}")

@app.get("/api/debug/db-status")
def debug_db_status():
    """Debug: Supabase ì—°ê²° ìƒíƒœ ë° LAWYERS_DB í˜„í™©"""
    info = {
        "in_memory_count": len(LAWYERS_DB),
        "in_memory_ids": [l.get("id") for l in LAWYERS_DB],
    }
    try:
        from supabase_client import get_supabase  # type: ignore
        sb = get_supabase()
        info["supabase_connected"] = sb is not None
        if sb:
            res = sb.table("lawyers").select("id, is_mock, verified").execute()
            info["supabase_total"] = len(res.data)
            info["supabase_real"] = [r["id"] for r in res.data if not r.get("is_mock")]
    except Exception as e:
        info["supabase_error"] = str(e)
    return info

# --- Auth System ---

class LoginRequest(BaseModel):
    email: str
    password: str

# Clients DB â€” Supabase ì˜êµ¬ ì €ì¥
_seed_clients = [
    {"id": "client1", "email": "client@example.com", "password": "password", "name": "ê¹€ì² ìˆ˜"}
]
try:
    _sb_clients = sb_load_all("clients")
    CLIENTS_DB = _sb_clients if _sb_clients else _seed_clients[:]
except Exception:
    CLIENTS_DB = _seed_clients[:]
print(f"ğŸ“Š ì˜ë¢°ì¸ ë³µì›: {len(CLIENTS_DB)}ëª…")

class ClientRegisterRequest(BaseModel):
    email: str
    password: str
    name: str

class ConsultationCreateRequest(BaseModel):
    lawyer_id: str
    text: str
    client_name: Optional[str] = None
    client_phone: Optional[str] = None

@app.post("/api/auth/login")
def login(request: LoginRequest):
    # 1. Check for Admin Login (from environment variables)
    _admin_user = os.getenv("ADMIN_USERNAME", "")
    _admin_pass = os.getenv("ADMIN_PASSWORD", "")
    if _admin_user and request.email == _admin_user and request.password == _admin_pass:
        import hashlib as _hl
        _jwt_secret = os.getenv("JWT_SECRET_KEY", "fallback-secret")
        _admin_token = _hl.sha256(f"{_admin_user}:{_jwt_secret}".encode()).hexdigest()
        return {
            "message": "Admin login successful", 
            "token": _admin_token,
            "user": {"name": "ê´€ë¦¬ì", "role": "admin", "email": _admin_user},
            "redirect_to": "/admin/dashboard"
        }

    # 2. Check for Lawyer Login
    # Check both 'id' (used by new signups) and 'email' (if present)
    # 2. Check for Lawyer Login
    # Check both 'id' (used by new signups) and 'email' (if present)
    user = next((u for u in LAWYERS_DB if u.get("id") == request.email or u.get("email") == request.email), None)
    


    if not user:
         # For demo, if email is known mock user, allow
         if request.email == "lawyer1@example.com":
             user = LAWYERS_DB[0]
         else:
            print(f"Login failed for {request.email}")
            raise HTTPException(status_code=401, detail="Invalid credentials")
    
    # In real app, check password hash. Here we skip.
    return {
        "message": "Login successful", 
        "lawyer": user,
        "token": "lawyer_token_123",
        "redirect_to": "/lawyer/dashboard"
    }

@app.post("/api/auth/client/login")
def client_login(request: LoginRequest):
    user = next((u for u in CLIENTS_DB if u["email"] == request.email and u["password"] == request.password), None)
    
    # Mock fallback for demo
    if not user and request.email == "client@example.com":
         user = CLIENTS_DB[0]

    if user:
        return {
            "message": "Client login successful",
            "user": user,
            "token": "client_token_123",
            "redirect_to": "/"
        }
        
    raise HTTPException(status_code=401, detail="Invalid client credentials")

@app.post("/api/auth/client/register")
def client_register(request: ClientRegisterRequest):
    # Check existing
    if any(u["email"] == request.email for u in CLIENTS_DB):
        raise HTTPException(status_code=400, detail="Email already exists")
    
    new_user = {
        "id": f"client_{len(CLIENTS_DB)+1}",
        "email": request.email,
        "password": request.password,
        "name": request.name
    }
    CLIENTS_DB.append(new_user)
    sb_append("clients", new_user, fk_field="email")
    return {"message": "Registration successful", "user": new_user}

# --- Lawyer Signup ---
@app.post("/api/auth/signup/lawyer")
async def signup_lawyer(
    name: str = Form(...),
    email: str = Form(...),
    password: str = Form(...),
    licenseId: str = Form(...),
    firm: str = Form(...),
    phone: str = Form(...),
    licenseImage: UploadFile = File(...)
):
    # Check if email exists
    if any(l["id"] == email for l in LAWYERS_DB):
        raise HTTPException(status_code=400, detail="Email already registered")
    
    # Validation: licenseImage must be an image
    if licenseImage.content_type and not licenseImage.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="License file must be an image")

    # Save License Image â†’ Supabase Storage (persistent)
    file_ext = os.path.splitext(licenseImage.filename or "upload.png")[1] or ".png"
    filename = f"{email}_license{file_ext}"
    
    license_bytes = await licenseImage.read()
    license_url = ""
    
    # Try Supabase Storage first
    try:
        from storage_utils import upload_and_get_url  # type: ignore
        sb_url = upload_and_get_url("licenses", filename, license_bytes, licenseImage.content_type or "image/png")
        if sb_url:
            license_url = sb_url
            print(f"âœ… ìê²©ì¦ ì´ë¯¸ì§€ Supabase ì—…ë¡œë“œ: {license_url}")
    except Exception as e:
        print(f"âš ï¸ Supabase Storage ì‹¤íŒ¨: {e}")
    
    # Fallback: save to /tmp
    if not license_url:
        import shutil as _shutil
        upload_dir = "/tmp/uploads/licenses"
        os.makedirs(upload_dir, exist_ok=True)
        file_path = os.path.join(upload_dir, filename)
        try:
            with open(file_path, "wb") as buffer:
                buffer.write(license_bytes)
        except Exception as e:
            print(f"Error saving license image: {e}")
            raise HTTPException(status_code=500, detail="Failed to save license image")
        license_url = f"/uploads/licenses/{filename}"

    new_lawyer = {
        "id": email,
        "email": email,
        "name": name,
        "password": password,
        "firm": firm,
        "location": "ì„œìš¸ (ë“±ë¡ ëŒ€ê¸°)",
        "career": f"ë³€í˜¸ì‚¬ ìê²©ì¦ ë²ˆí˜¸: {licenseId}",
        "education": "",
        "careerTags": ["ì‹ ê·œ"],
        "gender": "unknown",
        "expertise": ["ì¼ë°˜"],
        "matchScore": 0,
        "bestCase": {"title": "ë“±ë¡ ëŒ€ê¸° ì¤‘", "summary": "ì•„ì§ ë“±ë¡ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤."},
        "imageUrl": "/static/images/default_avatar.png",
        "cutoutImageUrl": "/static/images/default_avatar.png",
        "bgRemoveStatus": "pending",
        "content_items": [],
        "content_highlights": "ì¸ì¦ ì‹¬ì‚¬ ì¤‘",
        "phone": phone,
        "homepage": None,
        "kakao_id": None,
        "verified": False,
        "licenseId": licenseId,
        "licenseImageUrl": license_url
    }

    # --- íŒŒìš´ë”© ë©¤ë²„ í˜œíƒ ìë™ ë¶€ì—¬ ---
    try:
        from billing import set_founder_benefits, set_standard_trial, FOUNDER_LIMIT  # type: ignore
    except ImportError:
        FOUNDER_LIMIT = 300
        set_founder_benefits = None
        set_standard_trial = None

    if set_founder_benefits and len(LAWYERS_DB) < FOUNDER_LIMIT:
        set_founder_benefits(new_lawyer)
    elif set_standard_trial:
        set_standard_trial(new_lawyer)
    
    LAWYERS_DB.append(new_lawyer)
    save_lawyers_db(LAWYERS_DB)
    
    # ì§ì ‘ Supabaseì— ê°œë³„ ì €ì¥ (save_lawyers_dbì˜ ëŒ€ëŸ‰ upsert ì‹¤íŒ¨ ëŒ€ë¹„)
    try:
        from supabase_client import get_supabase  # type: ignore
        _sb = get_supabase()
        if _sb:
            from datetime import datetime as _dt2
            _sb.table("lawyers").upsert({
                "id": new_lawyer["id"],
                "data": new_lawyer,
                "is_mock": False,
                "verified": False,
                "updated_at": _dt2.now().isoformat(),
            }, on_conflict="id").execute()
            print(f"âœ… ë³€í˜¸ì‚¬ ê°œë³„ Supabase ì €ì¥ ì™„ë£Œ: {new_lawyer['id']}")
    except Exception as e:
        print(f"âš ï¸ ë³€í˜¸ì‚¬ ê°œë³„ Supabase ì €ì¥ ì‹¤íŒ¨: {e}")

    founder_msg = " ğŸ‰ ê°€ì… ì‹ ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê´€ë¦¬ì ê²€í†  í›„ ìŠ¹ì¸ë©ë‹ˆë‹¤." if new_lawyer.get("is_founder") else " ê°€ì… ì‹ ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ê²€í†  í›„ ìŠ¹ì¸ë©ë‹ˆë‹¤."
    return {"message": founder_msg, "lawyer_id": new_lawyer["id"], "is_founder": new_lawyer.get("is_founder", False), "status": "pending_review"}

# --- Serve uploaded files (Vercel serverless can't use StaticFiles) ---
from fastapi.responses import FileResponse  # type: ignore

@app.get("/uploads/{subdir}/{filename}")
def serve_uploaded_file(subdir: str, filename: str):
    """Serve uploaded files (e.g. license images) from /tmp/uploads/"""
    import re
    # Sanitize inputs to prevent path traversal
    if not re.match(r'^[a-zA-Z0-9_-]+$', subdir):
        raise HTTPException(status_code=400, detail="Invalid path")
    if '..' in filename or '/' in filename or '\\' in filename:
        raise HTTPException(status_code=400, detail="Invalid filename")
    
    file_path = os.path.join("/tmp/uploads", subdir, filename)
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="File not found")
    return FileResponse(file_path)

# --- Get Single Lawyer Profile ---

@app.get("/api/lawyers/{lawyer_id}")
def get_lawyer_profile(lawyer_id: str):
    """ë³€í˜¸ì‚¬ ê°œë³„ í”„ë¡œí•„ ì¡°íšŒ (ëŒ€ì‹œë³´ë“œ ê°±ì‹ ìš©)"""
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    return lawyer

# --- Admin: Lawyer Approval Endpoints ---

@app.get("/api/admin/lawyers/pending")
def get_pending_lawyers():
    """ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ì‹¤ì œ ê°€ì… ë³€í˜¸ì‚¬ ëª©ë¡ (ê°€ìƒ ë³€í˜¸ì‚¬ ì œì™¸)"""
    pending = [l for l in LAWYERS_DB if not l.get("verified", False) and not l.get("is_mock", False)]
    return pending

@app.post("/api/admin/lawyers/{lawyer_id}/verify")
def verify_lawyer(lawyer_id: str):
    """ë³€í˜¸ì‚¬ ê°€ì… ìŠ¹ì¸ (ìê²©ì¦ ê²€í†  ì™„ë£Œ)"""
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    lawyer["verified"] = True
    # ì¸ì¦ ê´€ë ¨ í•„ë“œ ì—…ë°ì´íŠ¸
    lawyer["location"] = lawyer.get("location", "").replace(" (ë“±ë¡ ëŒ€ê¸°)", "")
    lawyer["matchScore"] = 50  # ê²€ìƒ‰ì— ë…¸ì¶œë˜ë„ë¡ ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬
    lawyer["content_highlights"] = "ì‹ ê·œ ë“±ë¡ ë³€í˜¸ì‚¬"
    
    # íŒŒìš´ë”© ë©¤ë²„ í˜œíƒ ë¶€ì—¬ (ìŠ¹ì¸ ì‹œì ì— ì ìš©)
    try:
        from billing import set_founder_benefits, set_standard_trial, FOUNDER_LIMIT  # type: ignore
        verified_count = len([l for l in LAWYERS_DB if l.get("verified", False)])
        if verified_count <= FOUNDER_LIMIT and not lawyer.get("is_founder"):
            set_founder_benefits(lawyer)
    except ImportError:
        pass
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{lawyer['name']} ë³€í˜¸ì‚¬ê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "lawyer_id": lawyer_id}

@app.post("/api/admin/lawyers/{lawyer_id}/reject")
def reject_lawyer(lawyer_id: str):
    """ë³€í˜¸ì‚¬ ê°€ì… ë°˜ë ¤"""
    global LAWYERS_DB
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")

    lawyer_name = lawyer["name"]
    LAWYERS_DB = [l for l in LAWYERS_DB if l["id"] != lawyer_id]
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{lawyer_name} ë³€í˜¸ì‚¬ì˜ ê°€ì…ì´ ë°˜ë ¤ë˜ì—ˆìŠµë‹ˆë‹¤.", "lawyer_id": lawyer_id}

@app.delete("/api/admin/lawyers/{lawyer_id}")
def delete_lawyer(lawyer_id: str):
    """ë³€í˜¸ì‚¬ ì™„ì „ ì‚­ì œ"""
    global LAWYERS_DB
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    lawyer_name = lawyer["name"]
    LAWYERS_DB = [l for l in LAWYERS_DB if l["id"] != lawyer_id]
    
    # Supabaseì—ì„œë„ ì‚­ì œ
    try:
        from supabase_client import get_supabase  # type: ignore
        sb = get_supabase()
        if sb:
            sb.table("lawyers").delete().eq("id", lawyer_id).execute()
    except Exception:
        pass
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{lawyer_name} ë³€í˜¸ì‚¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", "lawyer_id": lawyer_id}

# --- Batch Approval / Rejection ---

class BatchLawyerRequest(BaseModel):
    lawyer_ids: List[str]

@app.post("/api/admin/lawyers/batch-verify")
def batch_verify_lawyers(request: BatchLawyerRequest):
    """ë³€í˜¸ì‚¬ ì¼ê´„ ìŠ¹ì¸"""
    verified_count = 0
    for lawyer_id in request.lawyer_ids:
        lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
        if lawyer and not lawyer.get("verified", False):
            lawyer["verified"] = True
            lawyer["location"] = lawyer.get("location", "").replace(" (ë“±ë¡ ëŒ€ê¸°)", "")
            lawyer["matchScore"] = 50
            lawyer["content_highlights"] = "ì‹ ê·œ ë“±ë¡ ë³€í˜¸ì‚¬"
            verified_count += 1  # type: ignore
            # íŒŒìš´ë”© ë©¤ë²„ í˜œíƒ
            try:
                from billing import set_founder_benefits, FOUNDER_LIMIT  # type: ignore
                total_verified = len([l for l in LAWYERS_DB if l.get("verified", False)])
                if total_verified <= FOUNDER_LIMIT and not lawyer.get("is_founder"):
                    set_founder_benefits(lawyer)
            except ImportError:
                pass
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{verified_count}ëª…ì˜ ë³€í˜¸ì‚¬ê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "verified_count": verified_count}

@app.post("/api/admin/lawyers/batch-reject")
def batch_reject_lawyers(request: BatchLawyerRequest):
    """ë³€í˜¸ì‚¬ ì¼ê´„ ë°˜ë ¤"""
    global LAWYERS_DB
    reject_ids = set(request.lawyer_ids)
    original_count = len(LAWYERS_DB)
    LAWYERS_DB = [l for l in LAWYERS_DB if l["id"] not in reject_ids or l.get("verified", False)]
    rejected_count = original_count - len(LAWYERS_DB)
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{rejected_count}ëª…ì˜ ë³€í˜¸ì‚¬ ê°€ì…ì´ ë°˜ë ¤ë˜ì—ˆìŠµë‹ˆë‹¤.", "rejected_count": rejected_count}

# â”€â”€ Social Login (Kakao / Naver) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SocialLoginRequest(BaseModel):
    provider: str       # "kakao" | "naver"
    social_id: str      # ì†Œì…œ í”Œë«í¼ ê³ ìœ  ID
    name: str           # ë‹‰ë„¤ì„ ë˜ëŠ” ì´ë¦„
    email: Optional[str] = None  # ì´ë©”ì¼ (ì„ íƒ)

@app.post("/api/auth/social/login")
def social_login(request: SocialLoginRequest):
    """ì¹´ì¹´ì˜¤/ë„¤ì´ë²„ ê°„í¸ ë¡œê·¸ì¸/ê°€ì… â€” ì†Œì…œ IDë¡œ ê¸°ì¡´ ìœ ì € ë§¤ì¹­ ë˜ëŠ” ì‹ ê·œ ìƒì„±"""
    # 1. ê¸°ì¡´ ìœ ì € ë§¤ì¹­ (social_id ë˜ëŠ” email)
    for user in CLIENTS_DB:
        if user.get("social_id") == request.social_id and user.get("provider") == request.provider:
            return {"message": "Login successful", "user": user, "is_new": False}
        if request.email and user.get("email") == request.email:
            # ì´ë©”ì¼ì´ ê°™ì€ ê¸°ì¡´ ìœ ì €ì— ì†Œì…œ ì •ë³´ ì—°ë™
            user["social_id"] = request.social_id
            user["provider"] = request.provider
            return {"message": "Login successful", "user": user, "is_new": False}

    # 2. ì‹ ê·œ ìœ ì € ìë™ ê°€ì…
    new_user = {
        "id": f"client_{len(CLIENTS_DB)+1}",
        "email": request.email or f"{request.provider}_{request.social_id}@social.local",
        "password": "",
        "name": request.name,
        "provider": request.provider,
        "social_id": request.social_id,
    }
    CLIENTS_DB.append(new_user)
    sb_append("clients", new_user, fk_field="email")
    return {"message": "Registration successful", "user": new_user, "is_new": True}

# --- Lead Notification System ---

class LeadModel(BaseModel):
    id: str
    lawyer_id: str
    case_summary: str
    contact_type: str # phone, homepage, kakao
    timestamp: str

class LeadCreateRequest(BaseModel):
    case_summary: str
    contact_type: str

from persistent_db import sb_append, sb_load_all, sb_load_by_fk, sb_update  # type: ignore

LEADS_DB = sb_load_all("leads") or []
print(f"ğŸ“Š ë¦¬ë“œ ë³µì› (Supabase): {len(LEADS_DB)}ê±´")

@app.post("/api/lawyers/{lawyer_id}/leads")
def create_lead(lawyer_id: str, request: LeadCreateRequest):
    # Verify lawyer exists
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
        
    lead = {
        "id": str(uuid4()),
        "lawyer_id": lawyer_id,
        "case_summary": request.case_summary,
        "contact_type": request.contact_type,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "stage": "inquiry",  # ì¹¸ë°˜ ë‹¨ê³„: inquiry â†’ consultation â†’ contract â†’ retained â†’ closed
        "client_name": "",
        "client_phone": "",
        "client_email": "",
        "notes": "",
        "priority": "normal",  # low, normal, high, urgent
        "area": "",
    }
    
    LEADS_DB.append(lead)
    sb_append("leads", lead)
    
    print(f"ë³€í˜¸ì‚¬ {lawyer_id}ì— ëŒ€í•œ ë¦¬ë“œ ìƒì„±: {request.contact_type}")
    return {"message": "ë¦¬ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤.", "lead_id": lead["id"]}

@app.get("/api/lawyers/{lawyer_id}/leads", response_model=List[LeadModel])
def get_lawyer_leads(lawyer_id: str):
    # Retrieve leads for this lawyer from Supabase
    leads = sb_load_by_fk("leads", "lawyer_id", lawyer_id) or [l for l in LEADS_DB if l["lawyer_id"] == lawyer_id]
    leads.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    return leads

class LeadUpdateRequest(BaseModel):
    stage: Optional[str] = None
    client_name: Optional[str] = None
    client_phone: Optional[str] = None
    client_email: Optional[str] = None
    notes: Optional[str] = None
    priority: Optional[str] = None
    area: Optional[str] = None
    case_summary: Optional[str] = None

@app.patch("/api/leads/{lead_id}")
def update_lead(lead_id: str, data: LeadUpdateRequest):
    """ë¦¬ë“œ ì •ë³´ ì—…ë°ì´íŠ¸ (ë‹¨ê³„ ë³€ê²½, ë©”ëª¨ ì¶”ê°€ ë“±)"""
    lead = next((l for l in LEADS_DB if l["id"] == lead_id), None)
    if not lead:
        raise HTTPException(status_code=404, detail="Lead not found")
    
    update_fields = data.dict(exclude_none=True)  # type: ignore
    for key, value in update_fields.items():
        lead[key] = value
    
    # Supabase ë™ê¸°í™”
    sb_update("leads", lead)
    
    return {"message": "ë¦¬ë“œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "lead": lead}

@app.delete("/api/leads/{lead_id}")
def delete_lead(lead_id: str):
    """ë¦¬ë“œ ì‚­ì œ"""
    global LEADS_DB
    lead = next((l for l in LEADS_DB if l["id"] == lead_id), None)
    if not lead:
        raise HTTPException(status_code=404, detail="Lead not found")
    
    LEADS_DB = [l for l in LEADS_DB if l["id"] != lead_id]
    # Note: Supabaseì—ì„œë„ ì‚­ì œ
    try:
        from supabase_client import get_supabase  # type: ignore
        sb = get_supabase()
        if sb:
            sb.table("leads").delete().eq("id", lead_id).execute()
    except Exception:
        pass
    
    return {"message": "ë¦¬ë“œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}


# --- Matter Management (ì‚¬ê±´ ê´€ë¦¬) ---

MATTERS_DB: list = []
try:
    _matters_loaded = sb_load_all("matters")
    if _matters_loaded:
        MATTERS_DB = _matters_loaded
        print(f"ğŸ“Š ì‚¬ê±´ ë³µì› (Supabase): {len(MATTERS_DB)}ê±´")
except Exception:
    pass

class MatterCreateRequest(BaseModel):
    title: str
    case_number: str = ""
    court: str = ""
    client_name: str = ""
    opponent_name: str = ""
    area: str = ""
    description: str = ""
    status: str = "active"  # active, on_hold, closed, archived

class MatterUpdateRequest(BaseModel):
    title: Optional[str] = None
    case_number: Optional[str] = None
    court: Optional[str] = None
    client_name: Optional[str] = None
    opponent_name: Optional[str] = None
    area: Optional[str] = None
    description: Optional[str] = None
    status: Optional[str] = None
    next_deadline: Optional[str] = None
    next_deadline_label: Optional[str] = None

class MatterActivityRequest(BaseModel):
    type: str = "note"  # note, deadline, document, event
    content: str
    date: Optional[str] = None

@app.post("/api/matters")
async def create_matter(data: MatterCreateRequest):
    """ìƒˆ ì‚¬ê±´/ì•ˆê±´ ë“±ë¡"""
    # lawyer_id from header or body
    matter = {
        "id": str(uuid4()),
        "title": data.title,
        "case_number": data.case_number,
        "court": data.court,
        "client_name": data.client_name,
        "opponent_name": data.opponent_name,
        "area": data.area,
        "description": data.description,
        "status": data.status,
        "next_deadline": "",
        "next_deadline_label": "",
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "activities": [],
    }
    MATTERS_DB.append(matter)
    sb_append("matters", matter)
    return {"message": "ì‚¬ê±´ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.", "matter": matter}

@app.get("/api/matters")
async def list_matters(status: Optional[str] = None):
    """ì‚¬ê±´ ëª©ë¡ ì¡°íšŒ"""
    matters = MATTERS_DB
    if status:
        matters = [m for m in matters if m.get("status") == status]
    return sorted(matters, key=lambda x: x.get("updated_at", ""), reverse=True)

@app.get("/api/matters/{matter_id}")
async def get_matter(matter_id: str):
    """ì‚¬ê±´ ìƒì„¸ ì¡°íšŒ"""
    matter = next((m for m in MATTERS_DB if m["id"] == matter_id), None)
    if not matter:
        raise HTTPException(status_code=404, detail="Matter not found")
    return matter

@app.patch("/api/matters/{matter_id}")
async def update_matter(matter_id: str, data: MatterUpdateRequest):
    """ì‚¬ê±´ ì •ë³´ ì—…ë°ì´íŠ¸"""
    matter = next((m for m in MATTERS_DB if m["id"] == matter_id), None)
    if not matter:
        raise HTTPException(status_code=404, detail="Matter not found")
    
    for key, value in data.dict(exclude_none=True).items():  # type: ignore
        matter[key] = value
    matter["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sb_update("matters", matter)
    return {"message": "ì‚¬ê±´ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "matter": matter}

@app.delete("/api/matters/{matter_id}")
async def delete_matter(matter_id: str):
    """ì‚¬ê±´ ì‚­ì œ"""
    global MATTERS_DB
    matter = next((m for m in MATTERS_DB if m["id"] == matter_id), None)
    if not matter:
        raise HTTPException(status_code=404, detail="Matter not found")
    MATTERS_DB = [m for m in MATTERS_DB if m["id"] != matter_id]
    return {"message": "ì‚¬ê±´ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.post("/api/matters/{matter_id}/activities")
async def add_matter_activity(matter_id: str, data: MatterActivityRequest):
    """ì‚¬ê±´ì— í™œë™ ê¸°ë¡ ì¶”ê°€ (ë©”ëª¨, ê¸°ì¼, ë¬¸ì„œ ë“±)"""
    matter = next((m for m in MATTERS_DB if m["id"] == matter_id), None)
    if not matter:
        raise HTTPException(status_code=404, detail="Matter not found")
    
    activity = {
        "id": str(uuid4()),
        "type": data.type,
        "content": data.content,
        "date": data.date or datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    
    if "activities" not in matter:
        matter["activities"] = []
    matter["activities"].insert(0, activity)
    matter["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sb_update("matters", matter)
    return {"message": "í™œë™ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.", "activity": activity}



# ì˜ë¢°ì¸ ì‚¬ì—° ì €ì¥ DB
CLIENT_STORIES_DB = sb_load_all("client_stories") or []
print(f"ğŸ“Š ì˜ë¢°ì¸ ì‚¬ì—° ë³µì› (Supabase): {len(CLIENT_STORIES_DB)}ê±´")

class ClientStoryRequest(BaseModel):
    client_id: str
    title: str
    content: str
    area: Optional[str] = None

@app.post("/api/client/stories")
def save_client_story(request: ClientStoryRequest):
    story = {
        "id": str(uuid4()),
        "client_id": request.client_id,
        "title": request.title,
        "content": request.content,
        "area": request.area or "ë¯¸ë¶„ë¥˜",
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "status": "ì ‘ìˆ˜ì™„ë£Œ"
    }
    CLIENT_STORIES_DB.append(story)
    sb_append("client_stories", story, fk_field="client_id")
    return {"message": "ì‚¬ì—°ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", "story": story}

@app.get("/api/client/{client_id}/stories")
def get_client_stories(client_id: str):
    stories = sb_load_by_fk("client_stories", "client_id", client_id) or [s for s in CLIENT_STORIES_DB if s["client_id"] == client_id]
    stories.sort(key=lambda x: x.get("created_at", ""), reverse=True)
    return stories

@app.get("/api/client/{client_id}/chats")
def get_client_chats(client_id: str):
    from chat import chat_manager  # type: ignore
    chat_manager.load_chats()
    chats = []
    for session in chat_manager.sessions.values():
        if session.client_id == client_id:
            # Find lawyer name
            lawyer = next((l for l in LAWYERS_DB if l["id"] == session.lawyer_id), None)
            chat_data = session.to_dict()
            chat_data["lawyer_name"] = lawyer["name"] if lawyer else "ì•Œ ìˆ˜ ì—†ìŒ"
            chat_data["lawyer_firm"] = lawyer.get("firm", "") if lawyer else ""
            chat_data["lawyer_image"] = lawyer.get("imageUrl") if lawyer else None
            chats.append(chat_data)
    chats.sort(key=lambda x: x["last_updated"], reverse=True)
    return chats

# --- Client Portal APIs ---

class ClientMessageRequest(BaseModel):
    client_name: str
    content: str

@app.get("/api/client/{client_id}/portal")
async def get_client_portal(client_id: str):
    """
    í´ë¼ì´ì–¸íŠ¸ í¬í„¸: ì˜ë¢°ì¸ì˜ ì‚¬ê±´ í˜„í™©, í™œë™ ê¸°ë¡, ë³€í˜¸ì‚¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    client_idì— ì—°ê²°ëœ ì‚¬ê±´(matter)ì„ client_name ë§¤ì¹­ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    # ì˜ë¢°ì¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    client = None
    for c in CLIENTS_DB:
        if c.get("id") == client_id:
            client = c
            break
    
    client_name = client.get("name", "") if client else ""
    client_email = client.get("email", "") if client else ""
    
    # ì‚¬ê±´ ëª©ë¡ (client_name ë§¤ì¹­)
    client_matters = []
    for m in MATTERS_DB:
        if (m.get("client_name", "").strip() and 
            (m.get("client_name", "").strip() == client_name.strip() or
             client_email in str(m))):
            # ë¯¼ê° ì •ë³´ í•„í„°ë§ (descriptionì€ ìš”ì•½ë§Œ)
            safe_matter = {
                "id": m["id"],
                "title": m.get("title", ""),
                "case_number": m.get("case_number", ""),
                "court": m.get("court", ""),
                "area": m.get("area", ""),
                "status": m.get("status", "active"),
                "next_deadline": m.get("next_deadline", ""),
                "next_deadline_label": m.get("next_deadline_label", ""),
                "created_at": m.get("created_at", ""),
                "updated_at": m.get("updated_at", ""),
                "activities": [
                    a for a in m.get("activities", [])
                    if a.get("type") in ("event", "deadline", "client_message")
                ],
            }
            client_matters.append(safe_matter)
    
    # ë¦¬ë“œ ì •ë³´ (ìƒë‹´ ìƒíƒœ)
    client_leads = []
    for l in LEADS_DB:
        if client_name and l.get("client_name", "").strip() == client_name.strip():
            client_leads.append({
                "stage": l.get("stage", "inquiry"),
                "area": l.get("area", ""),
                "timestamp": l.get("timestamp", ""),
            })
    
    return {
        "client_name": client_name,
        "matters": sorted(client_matters, key=lambda x: x.get("updated_at", ""), reverse=True),
        "leads": client_leads,
        "total_matters": len(client_matters),
    }

@app.post("/api/matters/{matter_id}/client-messages")
async def add_client_message(matter_id: str, data: ClientMessageRequest):
    """ì˜ë¢°ì¸ì´ ì‚¬ê±´ì— ë©”ì‹œì§€ë¥¼ ë‚¨ê¹ë‹ˆë‹¤."""
    matter = next((m for m in MATTERS_DB if m["id"] == matter_id), None)
    if not matter:
        raise HTTPException(status_code=404, detail="Matter not found")
    
    activity = {
        "id": str(uuid4()),
        "type": "client_message",
        "content": f"[ì˜ë¢°ì¸ {data.client_name}] {data.content}",
        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    if "activities" not in matter:
        matter["activities"] = []
    matter["activities"].insert(0, activity)
    matter["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sb_update("matters", matter)
    return {"message": "ë©”ì‹œì§€ê°€ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤.", "activity": activity}


# --- Document Automation (ë¬¸ì„œ ìë™í™”) ---

DOC_TEMPLATES = {
    "complaint": {"name": "ì†Œì¥", "desc": "ë¯¼ì‚¬ì†Œì†¡ ì†Œì¥", "file": "complaint.txt"},
    "answer": {"name": "ë‹µë³€ì„œ", "desc": "í”¼ê³  ë‹µë³€ì„œ", "file": "answer.txt"},
    "brief": {"name": "ì¤€ë¹„ì„œë©´", "desc": "ë³€ë¡  ì¤€ë¹„ì„œë©´", "file": "brief.txt"},
    "payment_order": {"name": "ì§€ê¸‰ëª…ë ¹ì‹ ì²­ì„œ", "desc": "ì§€ê¸‰ëª…ë ¹ ì‹ ì²­", "file": "payment_order.txt"},
    "power_of_attorney": {"name": "ìœ„ì„ì¥", "desc": "ì†Œì†¡ ìœ„ì„ì¥", "file": "power_of_attorney.txt"},
    "settlement": {"name": "í•©ì˜ì„œ", "desc": "ë¶„ìŸ í•©ì˜ì„œ", "file": "settlement.txt"},
    "demand_letter": {"name": "ë‚´ìš©ì¦ëª…", "desc": "ë‚´ìš©ì¦ëª… ìš°í¸", "file": "demand_letter.txt"},
    "provisional_attachment": {"name": "ê°€ì••ë¥˜ì‹ ì²­ì„œ", "desc": "ë¶€ë™ì‚°/ì±„ê¶Œ ê°€ì••ë¥˜", "file": "provisional_attachment.txt"},
    "criminal_complaint": {"name": "ê³ ì†Œì¥", "desc": "í˜•ì‚¬ ê³ ì†Œì¥", "file": "criminal_complaint.txt"},
    "statement": {"name": "ì§„ìˆ ì„œ", "desc": "ì‚¬ì‹¤ ì§„ìˆ ì„œ", "file": "statement.txt"},
    "retainer_agreement": {"name": "ìˆ˜ì„ê³„ì•½ì„œ", "desc": "ë²•ë¥ ì‚¬ë¬´ ìœ„ì„ê³„ì•½", "file": "retainer_agreement.txt"},
    "appeal": {"name": "í•­ì†Œì¥", "desc": "í•­ì†Œ ì œê¸°", "file": "appeal.txt"},
    "provisional_injunction": {"name": "ê°€ì²˜ë¶„ì‹ ì²­ì„œ", "desc": "ì²˜ë¶„ê¸ˆì§€ ê°€ì²˜ë¶„", "file": "provisional_injunction.txt"},
}

import pathlib as _pathlib  # type: ignore
_TEMPLATE_DIR = _pathlib.Path(__file__).parent / "templates"

def _load_template(filename: str) -> str:
    """templates/ í´ë”ì—ì„œ ì–‘ì‹ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        return (_TEMPLATE_DIR / filename).read_text(encoding="utf-8")
    except Exception:
        return ""


class DocGenerateRequest(BaseModel):
    doc_type: str  # complaint, answer, brief, etc.
    matter_id: Optional[str] = None
    plaintiff_name: str = ""
    defendant_name: str = ""
    court: str = ""
    case_number: str = ""
    case_summary: str = ""
    claim_amount: str = ""
    additional_info: str = ""

@app.get("/api/documents/templates")
async def get_doc_templates():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ í…œí”Œë¦¿ ëª©ë¡"""
    return DOC_TEMPLATES

@app.post("/api/documents/generate")
async def generate_document(data: DocGenerateRequest):
    """AI ê¸°ë°˜ ë²•ë¥  ë¬¸ì„œ ìë™ ìƒì„±"""
    template = DOC_TEMPLATES.get(data.doc_type)
    if not template:
        raise HTTPException(status_code=400, detail=f"Unknown document type: {data.doc_type}")
    
    # Matter ë°ì´í„° ìë™ ì±„ìš°ê¸°
    matter_info = ""
    if data.matter_id:
        matter = next((m for m in MATTERS_DB if m["id"] == data.matter_id), None)
        if matter:
            matter_info = f"""
ì‚¬ê±´ëª…: {matter.get('title', '')}
ì‚¬ê±´ë²ˆí˜¸: {matter.get('case_number', '')}
ë²•ì›: {matter.get('court', '')}
ì˜ë¢°ì¸: {matter.get('client_name', '')}
ìƒëŒ€ë°©: {matter.get('opponent_name', '')}
ì‚¬ê±´ê°œìš”: {matter.get('description', '')}
"""
    
    # í…œí”Œë¦¿ íŒŒì¼ì—ì„œ ì–‘ì‹ ë¡œë“œ (templates/ í´ë”)
    template_file = template.get("file", "")
    file_template = _load_template(template_file) if template_file else ""
    
    # ë³€ìˆ˜ ì¹˜í™˜
    format_guide = file_template
    format_guide = format_guide.replace("[ì›ê³  ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[í”¼ê³  ì„±ëª…]", data.defendant_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ì±„ê¶Œì ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ì±„ë¬´ì ì„±ëª…]", data.defendant_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ê³ ì†Œì¸ ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[í”¼ê³ ì†Œì¸ ì„±ëª…]", data.defendant_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ê°‘ ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ì„ ì„±ëª…]", data.defendant_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ë°œì‹ ì¸ ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ìˆ˜ì‹ ì¸ ì„±ëª…]", data.defendant_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ìœ„ì„ì¸ ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ì˜ë¢°ì¸ ì„±ëª…]", data.plaintiff_name or "â—‹â—‹â—‹")
    format_guide = format_guide.replace("[ë²•ì›ëª…]", data.court or "â—‹â—‹ì§€ë°©ë²•ì›")
    format_guide = format_guide.replace("[ì²­êµ¬ê¸ˆì•¡]", data.claim_amount or "â—‹â—‹â—‹â—‹")
    format_guide = format_guide.replace("[í•©ì˜ê¸ˆì•¡]", data.claim_amount or "â—‹â—‹â—‹â—‹")

    prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ 15ë…„ì°¨ ì „ë¬¸ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.
ì•„ë˜ 'í‘œì¤€ ì–‘ì‹'ì˜ êµ¬ì¡°ë¥¼ **ì™„ì „íˆ ë”°ë¥´ë˜**, ëŒ€ê´„í˜¸([]) ì•ˆì˜ ì„¤ëª…ë¬¸ì€ ì‚¬ê±´ ë‚´ìš©ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

=== í‘œì¤€ ì–‘ì‹ ===
{format_guide}


=== ì‚¬ê±´ ë‚´ìš© ===
{data.case_summary or '(ë¯¸ì…ë ¥)'}

{f'=== ì‚¬ê±´ ê´€ë¦¬ ë°ì´í„° ===' + matter_info if matter_info else ''}

=== ì¶”ê°€ ì§€ì‹œì‚¬í•­ ===
{data.additional_info or 'ì—†ìŒ'}

[í•„ìˆ˜ ê·œì¹™]
1. ìœ„ ì–‘ì‹ì˜ êµ¬ì¡°ì™€ í¬ë§·(ë“¤ì—¬ì“°ê¸°, ì •ë ¬, í•­ë²ˆí˜¸)ì„ ì •í™•íˆ ë”°ë¥¼ ê²ƒ
2. ì‹¤ì œ ì‚¬ê±´ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ
3. ê´€ë ¨ ë²•ë¥  ì¡°í•­ì„ ëª…ì‹œí•˜ê³  íŒë¡€ê°€ ìˆë‹¤ë©´ ì¸ìš©í•  ê²ƒ
4. ë²•ì› ì œì¶œ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ì™„ì„±ë„ë¡œ ì‘ì„±í•  ê²ƒ
"""

    try:
        import openai  # type: ignore
        client_ai = openai.OpenAI()
        response = client_ai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ëŒ€í•œë¯¼êµ­ ì „ë¬¸ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤. ë²•ì› ì œì¶œìš© ì„œë©´ì„ ì‘ì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=4000,
        )
        content = response.choices[0].message.content  # type: ignore
        return {
            "doc_type": data.doc_type,
            "template_name": template["name"],
            "content": content,
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


# --- AI Draft Generation (AI ì´ˆì•ˆ ìƒì„±) ---

class AIDraftRequest(BaseModel):
    case_summary: str
    doc_type: str = "brief"  # brief, complaint, answer
    lawyer_id: Optional[str] = None
    matter_id: Optional[str] = None
    style_instructions: str = ""

@app.post("/api/ai/draft")
async def generate_ai_draft(data: AIDraftRequest):
    """ê³¼ê±° ìŠ¹ì†Œì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ AI ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # 1. RAGë¡œ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
    similar_cases = []
    try:
        from case_embeddings import search_similar_cases  # type: ignore
        similar_cases = search_similar_cases(query=data.case_summary, top_k=3, threshold=0.4)
    except Exception:
        pass
    
    # 2. Matter ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    matter_context = ""
    if data.matter_id:
        matter = next((m for m in MATTERS_DB if m["id"] == data.matter_id), None)
        if matter:
            matter_context = f"""
[ì‚¬ê±´ ì •ë³´]
ì‚¬ê±´ëª…: {matter.get('title', '')}
ì‚¬ê±´ë²ˆí˜¸: {matter.get('case_number', '')}
ë²•ì›: {matter.get('court', '')}
ì˜ë¢°ì¸: {matter.get('client_name', '')}
ìƒëŒ€ë°©: {matter.get('opponent_name', '')}
"""
    
    # 3. ìœ ì‚¬ ì‚¬ë¡€ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    rag_context = ""
    if similar_cases:
        rag_context = "\n\n[ì°¸ê³  ìœ ì‚¬ ì‚¬ë¡€]\n"
        for i, case in enumerate(similar_cases[:3], 1):
            rag_context += f"\n--- ì‚¬ë¡€ {i} (ìœ ì‚¬ë„: {case.get('similarity', 0):.0%}) ---\n"
            rag_context += f"ì œëª©: {case.get('title', '')}\n"
            rag_context += f"ìš”ì•½: {case.get('content_summary', '')}\n"
            rag_context += f"íƒœê·¸: {case.get('ai_tags', '')}\n"
    
    doc_names = {"brief": "ì¤€ë¹„ì„œë©´", "complaint": "ì†Œì¥", "answer": "ë‹µë³€ì„œ"}
    doc_name = doc_names.get(data.doc_type, "ë²•ë¥  ì„œë©´")
    
    prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ 15ë…„ì°¨ ì „ë¬¸ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.
ì•„ë˜ ì‚¬ê±´ ë‚´ìš©ê³¼ ìœ ì‚¬ ìŠ¹ì†Œì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ [{doc_name}] ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.

[ì‚¬ê±´ ê°œìš”]
{data.case_summary}

{matter_context}
{rag_context}

{f'[ë³€í˜¸ì‚¬ ìŠ¤íƒ€ì¼ ì§€ì‹œ]' + chr(10) + data.style_instructions if data.style_instructions else ''}

[ì‘ì„± ê·œì¹™]
1. ìœ ì‚¬ ìŠ¹ì†Œì‚¬ë¡€ì˜ ë…¼ì¦ êµ¬ì¡°ì™€ ë²•ì  ë…¼ë¦¬ë¥¼ ì°¸ê³ í•˜ë˜, í˜„ì¬ ì‚¬ê±´ì— ë§ê²Œ ë³€í˜•
2. ì‹¤ì œ ë²•ì› ì œì¶œ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ì „ë¬¸ì  ì„œë©´ ì‘ì„±
3. ê´€ë ¨ ë²•ë¥  ì¡°í•­ ë° íŒë¡€ ì¸ìš©
4. ì²´ê³„ì ì¸ ë²ˆí˜¸ ë§¤ê¹€ (ì œ1í•­, ê°€, (1) ë“±)
5. ì²­êµ¬ ì·¨ì§€ì™€ ì›ì¸ì„ ëª…í™•í•˜ê²Œ
"""

    try:
        import openai  # type: ignore
        client_ai = openai.OpenAI()
        response = client_ai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì „ë¬¸ ë³€í˜¸ì‚¬ë¡œ, ê³¼ê±° ìŠ¹ì†Œ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆ ì‚¬ê±´ì˜ ì„œë©´ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=4000,
        )
        content = response.choices[0].message.content  # type: ignore
        return {
            "draft": content,
            "similar_cases_used": len(similar_cases),
            "doc_type": data.doc_type,
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}")


# --- E-Signature (ì „ìì„œëª…) ---

ESIGN_DB: list = []

class ESignCreateRequest(BaseModel):
    title: str  # ì˜ˆ: "ìˆ˜ì„ê³„ì•½ì„œ", "ìœ„ì„ì¥"
    content: str  # ì„œëª…í•  ë¬¸ì„œ ë‚´ìš©
    signer_name: str
    signer_email: str = ""
    lawyer_name: str = ""

class ESignSignRequest(BaseModel):
    signer_name: str
    signature_data: str = ""  # base64 ì„œëª… ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸

@app.post("/api/esign/create")
async def create_esign(data: ESignCreateRequest):
    """ì „ìì„œëª… ìš”ì²­ ìƒì„±"""
    doc = {
        "id": str(uuid4()),
        "title": data.title,
        "content": data.content,
        "signer_name": data.signer_name,
        "signer_email": data.signer_email,
        "lawyer_name": data.lawyer_name,
        "status": "pending",  # pending, signed, expired
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "signed_at": None,
        "signature_data": None,
    }
    ESIGN_DB.append(doc)
    return {"message": "ì„œëª… ìš”ì²­ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.", "esign": doc}

@app.get("/api/esign/{esign_id}")
async def get_esign(esign_id: str):
    """ì„œëª… ë¬¸ì„œ ì¡°íšŒ"""
    doc = next((d for d in ESIGN_DB if d["id"] == esign_id), None)
    if not doc:
        raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return doc

@app.post("/api/esign/{esign_id}/sign")
async def sign_document(esign_id: str, data: ESignSignRequest):
    """ì „ìì„œëª… ì™„ë£Œ"""
    doc = next((d for d in ESIGN_DB if d["id"] == esign_id), None)
    if not doc:
        raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if doc["status"] == "signed":
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì„œëª…ëœ ë¬¸ì„œì…ë‹ˆë‹¤.")
    
    doc["status"] = "signed"
    doc["signed_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    doc["signature_data"] = data.signature_data or f"[ì „ìì„œëª…: {data.signer_name}]"
    
    return {"message": "ì„œëª…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", "esign": doc}

@app.get("/api/esign")
async def list_esigns():
    """ëª¨ë“  ì„œëª… ë¬¸ì„œ ëª©ë¡"""
    return sorted(ESIGN_DB, key=lambda x: x.get("created_at", ""), reverse=True)

@app.get("/api/lawyers/online")
def get_online_lawyers():
    from chat import presence_manager  # type: ignore
    online = []
    for lawyer in LAWYERS_DB:
        status = presence_manager.get_status(lawyer["id"])
        if status in ("online", "away"):
            online.append({
                "id": lawyer["id"],
                "name": lawyer["name"],
                "firm": lawyer.get("firm", ""),
                "expertise": lawyer.get("expertise", []),
                "imageUrl": lawyer.get("imageUrl"),
                "status": status,
                "location": lawyer.get("location", "")
            })
    return online

@app.get("/api/public/lawyers/{lawyer_id}")
def get_public_lawyer_detail(lawyer_id: str):
    """Public endpoint for lawyer profile page"""
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    # Return full public profile data
    return {
        "id": lawyer["id"],
        "name": lawyer["name"],
        "firm": lawyer.get("firm", ""),
        "location": lawyer.get("location", ""),
        "career": lawyer.get("career", ""),
        "education": lawyer.get("education", ""),
        "expertise": lawyer.get("expertise", []),
        "cases": lawyer.get("cases", []),
        "content_items": lawyer.get("content_items", []),
        "imageUrl": lawyer.get("imageUrl"),
        "cutoutImageUrl": lawyer.get("cutoutImageUrl"),
        "phone": lawyer.get("phone"),
        "homepage": lawyer.get("homepage"),
        "kakao_id": lawyer.get("kakao_id"),
        "introduction_short": lawyer.get("introduction_short", ""),
        "introduction_long": lawyer.get("introduction_long", ""),
        "expertise_score": lawyer.get("expertise_score"),
    }

# --- SEO Analysis Endpoints ---
from seo_helper import seo_helper  # type: ignore

class SEOAnalysisRequest(BaseModel):
    title: str
    content: str
    keyword: str

@app.post("/api/seo/analyze")
def analyze_seo(request: SEOAnalysisRequest):
    return seo_helper.analyze_content(request.title, request.content, request.keyword)

@app.get("/api/seo/keywords")
def get_seo_keywords(category: str = Query(..., description="Case category")):
    # Mock keyword database
    keywords = {
        "ì´í˜¼": ["ì´í˜¼ì†Œì†¡", "ì¬ì‚°ë¶„í• ", "ì–‘ìœ¡ê¶Œ", "ìƒê°„ë…€ìœ„ìë£Œ", "í˜‘ì˜ì´í˜¼"],
        "í˜•ì‚¬": ["ì„±ë²”ì£„", "ìŒì£¼ìš´ì „", "ì‚¬ê¸°ì£„", "í­í–‰", "ë³´ì´ìŠ¤í”¼ì‹±"],
        "ë¶€ë™ì‚°": ["ì „ì„¸ì‚¬ê¸°", "ëª…ë„ì†Œì†¡", "ë³´ì¦ê¸ˆë°˜í™˜", "ê¶Œë¦¬ê¸ˆ", "ì„ëŒ€ì°¨ê³„ì•½"],
        "ê¸°ì—…": ["ë²•ì¸íŒŒì‚°", "íš¡ë ¹", "ë°°ì„", "ê³„ì•½ê²€í† ", "ë…¸ë¬´ê´€ë¦¬"]
    }
    
    # Return matched list or empty
    for key, values in keywords.items():
        if key in category:
            return {"keywords": values}
            
    return {"keywords": []}

# --- Admin Magazine Management ---

@app.get("/api/admin/magazine/all")
def get_all_magazine_content():
    all_content = []
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            try:
                # Calculate source (Lawyer or Admin)
                is_admin_generated = "admin" in item.get("id", "") # Naive check, improve if needed
                source = "Admin Draft" if is_admin_generated else "Lawyer Post"
                
                all_content.append({
                    "id": item.get("id"),
                    "lawyer_id": lawyer["id"],  # type: ignore
                    "lawyer_name": lawyer["name"],  # type: ignore
                    "type": item.get("type", "blog"),
                    "title": item.get("title", "Untitled"),
                    "date": item.get("date", "Unknown"),
                    "verified": item.get("verified", False),
                    "source": source
                })
            except Exception as e:
                print(f"Error parsing item {item.get('id')}: {e}")
                continue
    
    # Sort by date descending
    all_content.sort(key=lambda x: x["date"], reverse=True)
    return all_content

@app.post("/api/admin/content/{item_id}/toggle-visibility")
def toggle_content_visibility(item_id: str):
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item.get("id") == item_id:
                # Toggle
                current_status = item.get("verified", False)
                item["verified"] = not current_status
                save_lawyers_db(LAWYERS_DB)
                return {"message": "Visibility toggled", "new_status": item["verified"]}
    
    raise HTTPException(status_code=404, detail="Content not found")

@app.delete("/api/admin/content/{item_id}")
def delete_content(item_id: str):
    for lawyer in LAWYERS_DB:
        if "content_items" in lawyer:
            initial_len = len(lawyer["content_items"])
            lawyer["content_items"] = [item for item in lawyer["content_items"] if item.get("id") != item_id]
            
            if len(lawyer["content_items"]) < initial_len:
                save_lawyers_db(LAWYERS_DB)
                return {"message": "Content deleted successfully"}
                
    raise HTTPException(status_code=404, detail="Content not found")

class MagazineCreateRequest(BaseModel):
    title: str
    content: str
    keyword: str
    category: str
    purpose: str
    cover_image: Optional[str] = None
    original_url: Optional[str] = None

@app.post("/api/admin/magazine")
def create_magazine_post(request: MagazineCreateRequest):
    # Default to main lawyer for demo
    target_lawyer_id = "welder49264@naver.com" 
    lawyer = next((l for l in LAWYERS_DB if l["id"] == target_lawyer_id), None)
    
    if not lawyer:
        lawyer = LAWYERS_DB[0] # Fallback

    # Infer topic_tags from category/keyword for recommendation algorithm scoring
    topic_tags = []
    category_tag_map = {
        "ê°€ì‚¬": ["ê°€ì‚¬ë²•"], "ì´í˜¼": ["ê°€ì‚¬ë²•"], "ìƒì†": ["ê°€ì‚¬ë²•"],
        "í˜•ì‚¬": ["í˜•ì‚¬ë²•"], "ì„±ë²”ì£„": ["í˜•ì‚¬ë²•"], "êµí†µ": ["í˜•ì‚¬ë²•"],
        "ë¶€ë™ì‚°": ["ë¶€ë™ì‚°ë²•"], "ì„ëŒ€ì°¨": ["ë¶€ë™ì‚°ë²•"], "ì „ì„¸": ["ë¶€ë™ì‚°ë²•"],
        "ë¯¼ì‚¬": ["ë¯¼ì‚¬ë²•"], "ì†í•´ë°°ìƒ": ["ë¯¼ì‚¬ë²•"], "ì±„ê¶Œ": ["ë¯¼ì‚¬ë²•"],
        "í–‰ì •": ["í–‰ì •ë²•"], "ë…¸ë™": ["ë…¸ë™ë²•"], "ì„¸ê¸ˆ": ["ì¡°ì„¸ë²•"],
        "ì˜ë£Œ": ["ì˜ë£Œë²•"], "ê¸°ì—…": ["ë¯¼ì‚¬ë²•"],
    }
    for kw, tags in category_tag_map.items():
        if kw in request.category or kw in request.keyword:
            topic_tags.extend(tags)
    if not topic_tags:
        topic_tags = [request.category]  # Fallback to category itself
        
    new_item = {
        "id": str(uuid4()),
        "type": "column", # Default to column
        "title": request.title,
        "content": request.content,
        "content_markdown": request.content,
        "tags": [request.keyword],
        "topic_tags": topic_tags,  # For recommendation algorithm scoring
        "category": request.category,
        "purpose": request.purpose,
        "date": datetime.now().strftime("%Y-%m-%d"),
        "view_count": 0,
        "cover_image": request.cover_image or "/images/pattern_1.jpg", 
        "original_url": request.original_url or "",
        "summary": request.content[:200] + "...",  # type: ignore
        "slug": request.title.replace(" ", "-"),
        "verified": True,
        "seo": {
            "target_keyword": request.keyword,
            "purpose": request.purpose,
            "schema": seo_helper.generate_schema({
                "title": request.title, 
                "date": datetime.now().strftime("%Y-%m-%d"),
                "lawyer_name": lawyer["name"]  # type: ignore
            })
        }
    }
    
    if "content_items" not in lawyer:  # type: ignore
        lawyer["content_items"] = []  # type: ignore
        
    lawyer["content_items"].insert(0, new_item)  # type: ignore
    save_lawyers_db(LAWYERS_DB)
    
    # ê²€ìƒ‰ ì¸ë±ìŠ¤ì— ì¦‰ì‹œ ì¶”ê°€ (ë³€í˜¸ì‚¬ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì ìˆ˜ ë°˜ì˜)
    try:
        from search import search_engine  # type: ignore
        text = f"{new_item['title']} {new_item['summary']}"
        embedding = search_engine._get_embedding(text)
        import numpy as np  # type: ignore
        if len(search_engine.corpus_embeddings) > 0:
            search_engine.corpus_embeddings = np.vstack([search_engine.corpus_embeddings, embedding])
        else:
            search_engine.corpus_embeddings = np.array([embedding])
        content_idx = len(lawyer["content_items"]) - 1  # type: ignore
        search_engine.mapping.append({"lawyer_id": lawyer["id"], "type": "content", "index": 0})  # type: ignore
        print(f"âœ… ë¸”ë¡œê·¸/ë§¤ê±°ì§„ ì½˜í…ì¸ ê°€ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì¸ë±ìŠ¤ì— ì¶”ê°€ë¨: {new_item['title']}")
    except Exception as e:
        print(f"âš ï¸ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ì¶”í›„ ì¬ì‹œì‘ ì‹œ ë°˜ì˜): {e}")
    
    return {"message": "Post created successfully", "id": new_item["id"]}

@app.get("/api/stats/monthly")
def get_monthly_stats():
    now = datetime.now()
    month_ago = now - timedelta(days=30)
    two_months_ago = month_ago - timedelta(days=30)

    # 1. Cases (Content Items type='case')
    # Filter all cases from all lawyers
    all_cases = []
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item.get("type") == "case":
                all_cases.append(item)

    # Current Period (Last 30d)
    current_cases = [c for c in all_cases if c.get("date") and c.get("date") >= month_ago.strftime("%Y-%m-%d")]
    # Previous Period (30d-60d ago)
    prev_cases = [c for c in all_cases if (c.get("date") and two_months_ago.strftime("%Y-%m-%d") <= c.get("date") < month_ago.strftime("%Y-%m-%d"))]

    # Group by Category (topic_tags[0])
    case_stats = {}
    for c in current_cases:
        tag = c.get("topic_tags", ["ê¸°íƒ€"])[0]
        case_stats[tag] = case_stats.get(tag, 0) + 1
    
    # Sort and take top 5
    top_case_categories = sorted(case_stats.items(), key=lambda x: x[1], reverse=True)[:5]  # type: ignore
    
    # Calculate Growth
    case_growth = {} # tag -> growth_rate
    for tag, count in top_case_categories:
        prev_count = len([c for c in prev_cases if c.get("topic_tags", ["ê¸°íƒ€"])[0] == tag])
        if prev_count == 0:
            growth = 100 if count > 0 else 0
        else:
            growth = ((count - prev_count) / prev_count) * 100
        case_growth[tag] = round(growth, 1)


    # 2. Consultations
    current_consults = [c for c in CONSULTATIONS_DB if c.get("created_at") and c.get("created_at") >= month_ago.strftime("%Y-%m-%d")]
    prev_consults = [c for c in CONSULTATIONS_DB if c.get("created_at") and two_months_ago.strftime("%Y-%m-%d") <= c.get("created_at") < month_ago.strftime("%Y-%m-%d")]

    consult_stats = {}
    for c in current_consults:
        area = c.get("primary_area", "ê¸°íƒ€")
        consult_stats[area] = consult_stats.get(area, 0) + 1
        
    top_consult_categories = sorted(consult_stats.items(), key=lambda x: x[1], reverse=True)[:5]  # type: ignore

    consult_growth = {}
    for area, count in top_consult_categories:
        prev_count = len([c for c in prev_consults if c.get("primary_area") == area])
        if prev_count == 0:
            growth = 100 if count > 0 else 0
        else:
            growth = ((count - prev_count) / prev_count) * 100
        consult_growth[area] = round(growth, 1)

    # 3. Market Demand (Case Count / Active Lawyer Count)
    # Active Lawyer: last_login within 30d OR verified=True
    active_lawyers = [l for l in LAWYERS_DB if l.get("verified") or (l.get("last_login") and l.get("last_login") >= month_ago.strftime("%Y-%m-%d"))]
    
    # Group active lawyers by expertise (primary)
    lawyer_stats = {}
    for l in active_lawyers:
        # Simplification: Use first expertise as primary
        expertise = l.get("expertise", ["ê¸°íƒ€"])[0]
        lawyer_stats[expertise] = lawyer_stats.get(expertise, 0) + 1

    # Calculate Demand Ratio for all categories present in cases
    demand_stats = []
    
    all_categories = set(case_stats.keys()) | set(lawyer_stats.keys())
    
    for cat in all_categories:
        case_count = case_stats.get(cat, 0)
        lawyer_count = lawyer_stats.get(cat, 0)
        
        ratio = case_count / lawyer_count if lawyer_count > 0 else case_count # If no lawyers, ratio matches case count (high demand)
        
        # Prev ratio (approximate)
        prev_case_count = len([c for c in prev_cases if c.get("topic_tags", ["ê¸°íƒ€"])[0] == cat])
        # Assume lawyer count was similar (simplification for mock data)
        prev_ratio = prev_case_count / lawyer_count if lawyer_count > 0 else prev_case_count
        
        growth = ((ratio - prev_ratio) / prev_ratio * 100) if prev_ratio > 0 else (100 if ratio > 0 else 0)

        demand_stats.append({
            "category": cat,
            "case_count": case_count,
            "lawyer_count": lawyer_count,
            "ratio": round(ratio, 2),  # type: ignore
            "growth": round(growth, 1)  # type: ignore
        })
        
    # Sort by ratio descending
    demand_stats.sort(key=lambda x: x["ratio"], reverse=True)

    return {
        "cases": {
            "top_categories": [{"name": k, "value": v, "growth": case_growth[k]} for k, v in top_case_categories]
        },
        "consultations": {
            "top_categories": [{"name": k, "value": v, "growth": consult_growth[k]} for k, v in top_consult_categories]
        },
        "demand": demand_stats[:10] # Top 10  # type: ignore
    }

from pdf_utils import extract_text_from_pdf  # type: ignore
from pii_utils import mask_pii  # type: ignore
import shutil

# ... existing imports ...

# --- Case/Magazine Automation ---

class CaseSummaryRequest(BaseModel):
    lawyer_id: str
    overview: str
    issues: str
    strategy: str
    result: str
    points: str
    tips: Optional[str] = None

@app.post("/api/cases/upload_pdf")
async def upload_case_pdf(lawyer_id: str = Form(...), file: UploadFile = File(...)):
    # 1. Save File
    upload_dir = f"uploads/cases/{lawyer_id}"
    os.makedirs(upload_dir, exist_ok=True)
    
    file_id = str(uuid4())
    ext = os.path.splitext(file.filename)[1]
    file_path = f"{upload_dir}/{file_id}{ext}"
    
    with open(file_path, "wb") as buffer:
        content = await file.read()
        buffer.write(content)
        
    # 2. Extract Text
    text, is_scanned = extract_text_from_pdf(content)
    
    if is_scanned:
        return {
            "success": False,
            "message": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (ìŠ¤ìº”ë³¸ ë˜ëŠ” ì´ë¯¸ì§€)",
            "is_scanned": True,
            "file_id": file_id
        }
        
    # 3. Mask PII
    masked_text = mask_pii(text)
    
    # 4. Generate Draft with LLM
    from consultation import analyze_judgment  # type: ignore
    
    # We pass the ORIGINAL text to the LLM so it can identify names (e.g. "Kim Soo-yeon") 
    # and anonymize them stylistically (e.g. "Kim C") as per the prompt instructions.
    analysis = analyze_judgment(text)
    
    # Auto-generate Image
    import urllib.parse
    prompt = f"legal document, case file, {analysis.get('result', 'justice')}, cinematic, warm lighting"
    encoded = urllib.parse.quote(prompt)
    image_url = f"https://image.pollinations.ai/prompt/{encoded}?width=800&height=600&nologo=true"

    draft = {
        "id": f"draft_{uuid4()}",
        "type": "case",
        "title": f"ì„±ê³µ ì‚¬ë¡€: {file.filename} (AI ë¶„ì„)",
        "content": f"""
<h3>1. ì‚¬ê±´ ê°œìš”</h3>
<p>{analysis.get('overview', 'ë‚´ìš©ì„ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')}</p>
<h3>2. ì£¼ìš” ìŸì </h3>
<p>{analysis.get('issues', 'ë‚´ìš©ì„ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')}</p>
<h3>3. ë³€í˜¸ì‚¬ì˜ ì¡°ë ¥ (ëŒ€ì‘ ì „ëµ)</h3>
<p>{analysis.get('strategy', 'ë‚´ìš©ì„ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')}</p>
<h3>4. ê²°ê³¼</h3>
<p>{analysis.get('result', 'ë‚´ìš©ì„ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')}</p>
<h3>5. íŒê²°/ê²°ì • í¬ì¸íŠ¸</h3>
<p>{analysis.get('points', 'ë‚´ìš©ì„ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')}</p>
<hr>
<p class="text-xs text-gray-500">* ë³¸ ê²Œì‹œë¬¼ì€ AIê°€ íŒê²°ë¬¸ì„ ë¶„ì„í•˜ì—¬ ì‘ì„±í•œ ì´ˆì•ˆì…ë‹ˆë‹¤. ì •í™•í•œ ë‚´ìš©ì€ ë°˜ë“œì‹œ ì›ë¬¸ê³¼ ëŒ€ì¡°í•˜ì—¬ ê²€í† í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.</p>
""",
        "summary": analysis.get('overview', '')[:100] + "...",
        "topic_tags": ["AIìƒì„±", "ìŠ¹ì†Œì‚¬ë¡€", analysis.get('result', 'ìŠ¹ì†Œ')],
        "verified": False,
        "date": datetime.now().strftime("%Y-%m-%d"),
        "url": None,
        "status": "draft",
        "lawyer_id": lawyer_id,
        "original_file": file_path,
        "image": image_url # Store generated image
    }
    
    # Save to DB
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if lawyer:
        lawyer["content_items"].insert(0, draft) # Add to top
        save_db()
        
    return {
        "success": True,
        "message": "ì´ˆì•ˆ ìƒì„± ì™„ë£Œ",
        "draft": draft
    }

@app.post("/api/cases/create_from_summary")
def create_case_draft(request: CaseSummaryRequest):
    draft_content = f"""
<h3>1. ì‚¬ê±´ ê°œìš”</h3>
<p>{request.overview}</p>
<h3>2. ì£¼ìš” ìŸì </h3>
<p>{request.issues}</p>
<h3>3. ë³€í˜¸ì‚¬ì˜ ì¡°ë ¥</h3>
<p>{request.strategy}</p>
<h3>4. ê²°ê³¼</h3>
<p>{request.result}</p>
<h3>5. íŒê²°/ê²°ì • í¬ì¸íŠ¸</h3>
<p>{request.points}</p>
"""
    if request.tips:
        draft_content += f"<h3>6. ì‹¤ë¬´ íŒ</h3><p>{request.tips}</p>"
        
    draft_content += """
<hr>
<p class="text-xs text-gray-500">* ë³€í˜¸ì‚¬ê°€ ì§ì ‘ ì…ë ¥í•œ í•µì‹¬ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ëœ ê²Œì‹œë¬¼ì…ë‹ˆë‹¤.</p>
"""

    # Auto-generate Image
    import urllib.parse
    prompt = f"legal victory, gavel, court, {request.result}, cinematic"
    encoded = urllib.parse.quote(prompt)
    image_url = f"https://image.pollinations.ai/prompt/{encoded}?width=800&height=600&nologo=true"

    draft = {
        "id": f"draft_{uuid4()}",
        "type": "case",
        "title": "ìŠ¹ì†Œ ì‚¬ë¡€ (ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”)",
        "content": draft_content,
        "summary": request.overview[:100] + "...",  # type: ignore
        "topic_tags": ["ìŠ¹ì†Œì‚¬ë¡€"],
        "verified": False,
        "date": datetime.now().strftime("%Y-%m-%d"),
        "url": None,
        "status": "draft",
        "lawyer_id": request.lawyer_id,
        "image": image_url # Store generated image
    }
    
    lawyer = next((l for l in LAWYERS_DB if l["id"] == request.lawyer_id), None)
    if lawyer:
        lawyer["content_items"].insert(0, draft)
        save_db()
        
    return {
        "success": True,
        "message": "ì´ˆì•ˆ ì €ì¥ ì™„ë£Œ",
        "draft": draft
    }


# --- Consultation CRM System ---
from consultation import analyze_consultation_text  # type: ignore

class ConsultationModel(BaseModel):
    id: str
    lawyer_id: str
    created_at: str
    updated_at: str
    original_text: str
    
    # Analysis Results (Flattened for simplicity or nested)
    case_title: str
    primary_area: str
    confidence: float
    summary: str
    key_facts: List[str]
    key_issues: List[str]
    missing_questions: List[str]
    checklist: List[str]
    risk_notes: List[str]
    next_steps: List[str]
    
    # Management
    status: str # new, reviewing, waiting_client, proceeding, closed
    tags: List[str]
    notes: Optional[str] = None
    links: List[str] = []
    chat_client_id: Optional[str] = None # Added for chat integration

class ConsultationCreateRequest(BaseModel):
    text: str
    lawyer_id: str
    chat_client_id: Optional[str] = None # Added for chat integration

class ActionSuggestion(BaseModel):
    id: str
    title: str
    description: str
    priority: int # 1 (High) to 3 (Low)
    cta_label: str
    cta_link: str
    icon: str # emoji or icon name

CONSULTATIONS_DB = sb_load_all("consultations") or []
print(f"ğŸ“Š ìƒë‹´ ë³µì› (Supabase): {len(CONSULTATIONS_DB)}ê±´")

@app.post("/api/consultations", response_model=ConsultationModel)
async def create_consultation(request: ConsultationCreateRequest):
    # Analyze text
    print(f"Creating consultation for lawyer {request.lawyer_id} with chat_id {request.chat_client_id}")
    analysis = analyze_consultation_text(request.text)
    
    consultation = {
        "id": str(uuid4()),
        "lawyer_id": request.lawyer_id,
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "original_text": request.text,
        **analysis, # Spread analysis results
        "status": "new",
        "tags": [],
        "notes": "",
        "links": [],
        "chat_client_id": request.chat_client_id # Store chat ID
    }
    
    CONSULTATIONS_DB.append(consultation)
    sb_append("consultations", consultation)

    # --- Send Notification to Dashboard via Chat Server (IPC) ---
    try:
        import websockets  # type: ignore
        # Connect as a system user to trigger the notification broadcast
        chat_ws_url = f"ws://127.0.0.1:8003/ws/chat/{request.lawyer_id}/consultation_system/user"
        async with websockets.connect(chat_ws_url) as websocket:
            notification_text = f"ìƒˆë¡œìš´ ìƒë‹´ ì‹ ì²­ì´ ë„ì°©í–ˆìŠµë‹ˆë‹¤: {analysis.get('case_title', 'ì œëª© ì—†ìŒ')}"
            await websocket.send(notification_text)
            print(f"Notification sent to chat server for {request.lawyer_id}")
    except Exception as e:
        print(f"Failed to send consultation notification via WS: {e}")

    return consultation

@app.get("/api/consultations", response_model=List[ConsultationModel])
def get_consultations(
    lawyer_id: str, 
    status: Optional[str] = None, 
    area: Optional[str] = None, 
    search: Optional[str] = None
):
    results = [c for c in CONSULTATIONS_DB if c["lawyer_id"] == lawyer_id]
    
    if status:
        results = [c for c in results if c["status"] == status]
    if area:
        results = [c for c in results if c["primary_area"] == area]
    if search:
        s = search.lower()
        results = [c for c in results if s in c["case_title"].lower() or s in c["summary"].lower()]
        
    # Sort by updated_at desc
    results.sort(key=lambda x: x["updated_at"], reverse=True)
    return results

@app.get("/api/consultations/{id}", response_model=ConsultationModel)
def get_consultation_detail(id: str):
    consultation = next((c for c in CONSULTATIONS_DB if c["id"] == id), None)
    if not consultation:
        raise HTTPException(status_code=404, detail="ìƒë‹´ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return consultation

class ConsultationUpdateRequest(BaseModel):
    status: Optional[str] = None
    tags: Optional[List[str]] = None
    notes: Optional[str] = None

@app.patch("/api/consultations/{id}", response_model=ConsultationModel)
def update_consultation(id: str, request: ConsultationUpdateRequest):
    consultation = next((c for c in CONSULTATIONS_DB if c["id"] == id), None)
    if not consultation:
        raise HTTPException(status_code=404, detail="ìƒë‹´ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    if request.status:
        consultation["status"] = request.status
    if request.tags is not None:
        consultation["tags"] = request.tags
    if request.notes is not None:
        consultation["notes"] = request.notes
        
    consultation["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return consultation

@app.get("/api/dashboard/actions", response_model=List[ActionSuggestion])
def get_dashboard_actions(lawyer_id: str):
    # Rule-based suggestions
    suggestions = []
    
    # 1. Check profile completeness (Mock logic)
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if lawyer:
        if not lawyer.get("imageUrl"):
             suggestions.append({
                "id": "profile_photo",
                "title": "ì„ ìƒë‹˜ì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì—¬ë³´ì„¸ìš”",
                "description": "í”„ë¡œí•„ ì‚¬ì§„ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ì ì¸ ì‚¬ì§„ì„ ë“±ë¡í•˜ë©´ ìƒë‹´ ìš”ì²­ì´ 30% ì¦ê°€í•©ë‹ˆë‹¤.",
                "priority": 1,
                "cta_label": "ì‚¬ì§„ ë“±ë¡í•˜ê¸°",
                "cta_link": "/lawyer/profile/edit",
                "icon": "ğŸ“¸"
            })
        if not lawyer.get("career") or len(lawyer.get("career", "")) < 10:
             suggestions.append({
                "id": "profile_career",
                "title": "ìƒì„¸ ê²½ë ¥ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”",
                "description": "ì˜ë¢°ì¸ë“¤ì€ ìƒì„¸í•œ ê²½ë ¥ì„ í™•ì¸í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.",
                "priority": 2,
                "cta_label": "ê²½ë ¥ ì¶”ê°€",
                "cta_link": "/lawyer/profile/edit",
                "icon": "v"
            })
            
    # 2. Check recent content
    # Check if lawyer has any 'case' content in the last 30 days
    has_recent_case = False
    if lawyer.get("content_items"):  # type: ignore
        # Check if any item is type 'case'
        # Simple check: just check if they have ANY case for now to stop the annoyance
        has_recent_case = any(item.get("type") == "case" for item in lawyer["content_items"])  # type: ignore
        
    if not has_recent_case:
        suggestions.append({
            "id": "write_case",
            "title": "ê°€ì‚¬ ë¶„ì•¼ ë¬¸ì˜ê°€ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤",
            "description": "ìµœê·¼ 7ì¼ê°„ ê°€ì‚¬ ë¶„ì•¼ ê²€ìƒ‰ì´ 15% ëŠ˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë ¨ ìŠ¹ì†Œì‚¬ë¡€ë¥¼ ë“±ë¡í•´ë³´ì„¸ìš”.",
            "priority": 2,
            "cta_label": "ìŠ¹ì†Œì‚¬ë¡€ ë“±ë¡í•˜ê¸°",
            "cta_link": "/lawyer/dashboard/cases/upload",
            "icon": "ğŸ“ˆ"
        })

    # 3. Check consultation updates
    # Mock: Check if any consultation is 'new' for > 3 days
    stale_consultations = [c for c in CONSULTATIONS_DB if c["lawyer_id"] == lawyer_id and c["status"] == "new"]
    if len(stale_consultations) > 0:
        suggestions.append({
             "id": "review_consultation",
             "title": "í™•ì¸í•˜ì§€ ì•Šì€ ìƒë‹´ì´ ìˆìŠµë‹ˆë‹¤",
             "description": f"{len(stale_consultations)}ê±´ì˜ ì‹ ê·œ ìƒë‹´ì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.",
             "priority": 1,
             "cta_label": "ìƒë‹´ ê²€í† í•˜ê¸°",
             "cta_link": "/lawyer/consultations",
             "icon": "bell"
        })

    return suggestions[:3] # Return top 3  # type: ignore

# Configure CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# StaticFiles removed for Vercel serverless (no filesystem access)

DB_FILE = "lawyers_db.json"


class CaseModel(BaseModel):
    title: str
    summary: str

class ContentItem(BaseModel):
    id: str
    type: str # blog, column, book, lecture
    title: str
    topic_tags: List[str]
    verified: bool
    date: Optional[str] = None
    url: Optional[str] = None
    source: Optional[str] = None # admin_injected, user_submission, etc.
    summary: Optional[str] = None # Added summary field
    slug: Optional[str] = None
    seo_title: Optional[str] = None
    seo_description: Optional[str] = None
    emotional_title: Optional[str] = None # New field for magazine
    emotional_summary: Optional[str] = None # New field for magazine


class BlogTheme(BaseModel):
    primaryColor: Optional[str] = None
    secondaryColor: Optional[str] = None
    accentColor: Optional[str] = None

class BlogContent(BaseModel):
    hero_description: Optional[str] = None
    consultation_title: Optional[str] = None
    consultation_message: Optional[str] = None

class LawyerModel(BaseModel):
    id: str
    name: str
    firm: str
    location: str
    career: str
    education: Optional[str] = None
    careerTags: List[str] = []
    gender: Optional[str] = None
    expertise: List[str]
    matchScore: float = 0.0
    bestCase: Optional[CaseModel] = None
    bestContent: Optional[ContentItem] = None # Added for magazine integration
    imageUrl: Optional[str] = None # Original URL (internal use or admin)
    cutoutImageUrl: Optional[str] = None # Processed transparent PNG
    bgRemoveStatus: str = "pending" # pending, processed, failed
    content_items: List[ContentItem] = []
    content_highlights: Optional[str] = None # Summary string for UI
    phone: Optional[str] = None
    homepage: Optional[str] = None
    kakao_id: Optional[str] = None
    verified: bool = True # Default to True for now (legacy data)
    introduction_short: Optional[str] = None # One-line tagline
    introduction_long: Optional[str] = None # Detailed bio
    blog_theme: Optional[BlogTheme] = None
    blog_content: Optional[BlogContent] = None
    # --- Subscription Fields ---
    is_subscribed: bool = False
    is_founder: bool = False
    trial_ends_at: Optional[str] = None
    billing_key: Optional[str] = None
    subscription_plan: Optional[str] = None
    licenseImageUrl: Optional[str] = None
    licenseId: Optional[str] = None
    is_mock: bool = False

class CaseAnalysisDetails(BaseModel):
    case_nature: str
    category: str # e.g. "í˜•ì‚¬ > ì„±ë²”ì£„", "ê°€ì‚¬ > ì´í˜¼"
    core_risk: str # Biggest risk factor
    time_strategy: str # "Golden time is now", "Secure evidence first", etc.
    urgency: str # "High", "Medium", "Low"
    procedure: str
    necessity_score: int
    cost_range: str
    
    # New Briefing Fields
    one_line_summary: str # "ë°°ìš°ìì˜ ë¶€ì •í–‰ìœ„ ì¦ê±°ê°€ ëª…í™•í•˜ì—¬ ìœ„ìë£Œ 3ì²œë§Œì› ì²­êµ¬ê°€ ê°€ëŠ¥í•œ ì‚¬ì•ˆì…ë‹ˆë‹¤."
    key_issues: List[str] # ["ì¬ì‚°ë¶„í•  ê¸°ì—¬ë„ ì…ì¦", "ì–‘ìœ¡ê¶Œ ì§€ì • ìœ ë¦¬", "ìƒê°„ì ì†Œì†¡ ë³‘í–‰ ì—¬ë¶€"]
    action_checklist: List[str] # ["í†µí™” ë…¹ìŒ ë° ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” ë‚´ìš© ë°±ì—…", "ì¹´ë“œ ì‚¬ìš© ë‚´ì—­ì„œ í™•ë³´", "ì „ë¬¸ê°€ ìƒë‹´ ì˜ˆì•½"]

class RecommendationResponse(BaseModel):
    lawyers: List[LawyerModel]
    analysis: str
    analysis_details: Optional[CaseAnalysisDetails] = None

@app.get("/")
def read_root():
    return {"message": "Lawnald API is running"}

@app.get("/api/recommend", response_model=RecommendationResponse)
def recommend_lawyers(
    q: str = Query(..., min_length=1), 
    location: Optional[str] = Query(None),
    gender: Optional[str] = Query(None),
    education: Optional[str] = Query(None),
    career: Optional[str] = Query(None)
):
    results = search_engine.search(q, location=location, gender=gender, education=education, career=career)
    return results

@app.post("/api/lawyers/{lawyer_id}/upload-photo")
async def upload_lawyer_photo(lawyer_id: str, file: UploadFile = File(...)):
    # 1. Find the lawyer
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")

    # 2. Validate file (simple check)
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image")

    # 3. Save original â€” now uploads to Supabase Storage
    filename = f"{lawyer_id}_{file.filename}"
    photo_url = await image_utils.save_upload_file(file, filename)
    
    # Update DB â€” use Supabase Storage URL (persists across deployments)
    lawyer["imageUrl"] = photo_url
    lawyer["cutoutImageUrl"] = photo_url  # Use original as cutout
    lawyer["bgRemoveStatus"] = "skipped"
    
    save_db()
    
    return {
        "message": "Photo uploaded successfully", 
        "cutoutImageUrl": photo_url,
        "status": "processed"
    }

# --- Content Submission & Admin System ---

class ContentSubmission(BaseModel):
    id: str
    lawyer_id: str
    type: str # blog, column, book, lecture
    title: str
    summary: str
    content: str # Full content or link
    topic_tags: List[str]
    status: str = "pending" # pending, approved, rejected
    date: str
    file_url: Optional[str] = None # PDF file URL or Image URL
    career: Optional[str] = None
    education: Optional[str] = None

SUBMISSIONS_DB = sb_load_all("submissions") or []
print(f"ğŸ“Š ì½˜í…ì¸  ì œì¶œ ë³µì› (Supabase): {len(SUBMISSIONS_DB)}ê±´")

@app.post("/api/lawyers/{lawyer_id}/submit")
async def submit_content(
    lawyer_id: str,
    type: str = Form(...),
    title: str = Form(None),
    summary: str = Form(None),
    content: str = Form(None),
    topic_tags: str = Form(None), 
    career: str = Form(None),
    education: str = Form(None),
    file: Optional[UploadFile] = File(None)
):
    # Verify lawyer exists
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")

    import uuid
    from datetime import datetime
    
    file_url = None
    if file:
        try:
            filename = f"{uuid.uuid4()}_{file.filename}"
            # Ensure safe filename
            import re
            filename = re.sub(r'[^a-zA-Z0-9_.-]', '', filename)
            
            # Upload to Supabase Storage
            file_bytes = await file.read()
            try:
                from storage_utils import upload_and_get_url  # type: ignore
                sb_url = upload_and_get_url("cases", filename, file_bytes, file.content_type or "application/octet-stream")
                if sb_url:
                    file_url = sb_url
            except Exception:
                pass
            
            # Fallback: save to /tmp
            if not file_url:
                os.makedirs("/tmp/documents", exist_ok=True)
                file_path = f"/tmp/documents/{filename}"
                with open(file_path, "wb") as buffer:
                    buffer.write(file_bytes)
                file_url = f"/uploads/documents/{filename}"
        except Exception as e:
            print(f"File upload failed: {e}")
            raise HTTPException(status_code=500, detail="File upload failed")

    tags_list = [t.strip() for t in topic_tags.split(",") if t.strip()] if topic_tags else []

    submission = {
        "id": str(uuid.uuid4()),
        "lawyer_id": lawyer_id,
        "lawyer_name": lawyer["name"],
        "type": type,
        "title": title or "Profile Update",
        "summary": summary or "",
        "content": content or "",
        "topic_tags": tags_list,
        "status": "approved", # Auto-approve for demo
        "date": datetime.now().strftime("%Y-%m-%d"),
        "file_url": file_url,
        "career": career,
        "education": education
    }
    
    SUBMISSIONS_DB.append(submission)
    sb_append("submissions", submission)

    # Auto-add to lawyer's content_items for Magazine visibility
    if type in ["column", "blog", "case"]:
        slug = seo.SEOGenerator.generate_slug(submission["title"])
        seo_title = seo.SEOGenerator.generate_seo_title(submission["title"], lawyer["name"], type)
        seo_desc = seo.SEOGenerator.generate_meta_description(submission["content"], submission["summary"])

        new_content_item = {
            "id": submission["id"],
            "type": "case" if type == "case" else "column", # Normalize type
            "title": submission["title"],
            "slug": slug,
            "seo_title": seo_title,
            "seo_description": seo_desc,
            "topic_tags": tags_list,
            "verified": True, # Auto-verify
            "date": submission["date"],
            "url": None, # Internal content
            "content": submission["content"] # Store content for magazine detail
        }
        if "content_items" not in lawyer:
            lawyer["content_items"] = []
        lawyer["content_items"].append(new_content_item)
        save_db() # Persist changes

    return {"message": "Submission received and published", "id": submission["id"]}

@app.get("/api/lawyers/{lawyer_id}/blog")
def get_lawyer_blog_posts(lawyer_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
        
    posts = [item for item in lawyer.get("content_items", []) if item.get("type") in ["blog", "column", "case"]]
    # Sort by date desc
    posts.sort(key=lambda x: x.get("date", ""), reverse=True)
    return posts

@app.get("/api/lawyers/{lawyer_id}/blog/{slug}")
def get_lawyer_blog_post_detail(lawyer_id: str, slug: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
        
    # Match by slug
    post = next((item for item in lawyer.get("content_items", []) if item.get("slug") == slug), None)
    
    # Fallback to ID match if slug not found (for legacy compatibility or if slug is actually an ID)
    if not post:
        post = next((item for item in lawyer.get("content_items", []) if item.get("id") == slug), None)
        
    if not post:
        raise HTTPException(status_code=404, detail="Blog post not found")
        
    return post

@app.get("/api/admin/submissions_legacy")
def get_submissions_legacy(status: str = "pending"):
    return [s for s in SUBMISSIONS_DB if s["status"] == status]

@app.post("/api/admin/submissions_legacy/{submission_id}/approve")
def approve_submission_legacy(submission_id: str):
    submission = next((s for s in SUBMISSIONS_DB if s["id"] == submission_id), None)
    if not submission:
        raise HTTPException(status_code=404, detail="Submission not found")
        
    submission["status"] = "approved"
    
    lawyer = next((l for l in LAWYERS_DB if l["id"] == submission["lawyer_id"]), None)
    if not lawyer:
        return {"message": "Approved, but lawyer not found"}

    if submission["type"] == "profile_update":
        # Update Profile Info
        if submission.get("career"):
            lawyer["career"] = submission["career"]
        if submission.get("education"):
            lawyer["education"] = submission["education"]
        if submission.get("file_url"):
            # If it's a photo update, we update the cutoutImageUrl directly for now
            # (In a real app, we might run bg removal here again or trust the user upload)
            lawyer["cutoutImageUrl"] = submission["file_url"]
            lawyer["imageUrl"] = submission["file_url"]
    else:
        # Add Content Item
        new_content = {
            "id": submission["id"],
            "type": submission["type"],
            "title": submission["title"],
            "topic_tags": submission["topic_tags"],
            "verified": True,
            "date": submission["date"],
            # Fix NoneType error: check if content exists before startswith
            "url": submission.get("url") or submission.get("file_url") or (submission["content"] if submission["content"] and submission["content"].startswith("http") else None)  # type: ignore
        }
        lawyer["content_items"].insert(0, new_content) # Add to top
        
        # Update Content Highlights
        count = len([c for c in lawyer["content_items"] if c["verified"]])
        lawyer["content_highlights"] = f"ê´€ë ¨ ì „ë¬¸ ì½˜í…ì¸  {count}ê±´ (ê²€ì¦ë¨)"
        
    return {"message": "Approved", "submission": submission}

@app.post("/api/admin/submissions_legacy/{submission_id}/reject")
def reject_submission_legacy(submission_id: str):
    submission = next((s for s in SUBMISSIONS_DB if s["id"] == submission_id), None)
    if not submission:
        raise HTTPException(status_code=404, detail="Submission not found")
        
    submission["status"] = "rejected"
    return {"message": "Rejected", "submission": submission}

# --- Direct Content Injection (Admin) ---

class InjectContentRequest(BaseModel):
    type: str # book, case, column
    count: int

@app.post("/api/admin/lawyers/{lawyer_id}/content/inject")
def inject_content(lawyer_id: str, request: InjectContentRequest):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    import uuid
    from datetime import datetime
    
    added_items = []
    
    import random
    from data_templates import REALISTIC_CASE_TITLES, get_all_case_titles  # type: ignore
    
    titles_map = {
        "book": ["ë²•ë¥  ê°€ì´ë“œë¶", "ì†Œì†¡ì˜ ì •ì„", "ìƒí™œ ë²•ë¥  ìƒì‹", "ì „ë¬¸ê°€ì˜ ì¡°ì–¸"],
        "column": ["ì „ì„¸ì‚¬ê¸° ì˜ˆë°© ì¹¼ëŸ¼", "ìƒì†ì„¸ ì ˆì„¸ ê°€ì´ë“œ", "êµí†µì‚¬ê³  ëŒ€ì²˜ë²•", "ê¸°ì—… ë²•ë¬´ ë™í–¥"]
    }
    
    for i in range(request.count):
        if request.type == "case":
            # Pick a random category then a random title for better variety
            category = random.choice(list(REALISTIC_CASE_TITLES.keys()))
            title_base = random.choice(REALISTIC_CASE_TITLES[category])
        else:
            title_base = random.choice(titles_map.get(request.type, ["ì „ë¬¸ ì½˜í…ì¸ "]))
            
        item = {
            "id": f"inject_{uuid.uuid4()}",
            "type": request.type,
            "title": title_base,
            "topic_tags": ["ì „ë¬¸ë¶„ì•¼", "ë²•ë¥ ìƒë‹´", "ìŠ¹ì†Œì‚¬ë¡€"],
            "verified": True,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "url": None,
            "source": "admin_injected" # Flag to hide from magazine
        }
        lawyer["content_items"].append(item)
        added_items.append(item)
        
    # Update Highlights
    count = len([c for c in lawyer["content_items"] if c["verified"]])
    lawyer["content_highlights"] = f"ê´€ë ¨ ì „ë¬¸ ì½˜í…ì¸  {count}ê±´ (ê²€ì¦ë¨)"
    
    return {
        "message": f"Successfully injected {request.count} {request.type} items",
        "current_total": count,
        "lawyer_name": lawyer["name"]
    }

# --- Persistence Utils ---


def load_db():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                loaded_data = json.load(f)
                LAWYERS_DB.clear()
                LAWYERS_DB.extend(loaded_data)
            print(f"Loaded {len(LAWYERS_DB)} lawyers from {DB_FILE}")
        except Exception as e:
            print(f"Failed to load DB: {e}. Using initial mock data.")
    else:
        print("No DB file found. Using initial mock data.")
        save_db()

def save_db():
    save_lawyers_db(LAWYERS_DB)


# Initialize DB on startup (module level)
load_db()

# Initialize Search Engine (Load/Generate Embeddings)
try:
    print("Initializing Search Engine...")
    search_engine.load_index() # Use load_index to use cache if available
except Exception as e:
    print(f"Failed to initialize search engine: {e}")

# --- Authentication & Signup ---

@app.post("/api/auth/signup/lawyer")
async def signup_lawyer(
    name: str = Form(...),
    email: str = Form(...),
    password: str = Form(...),
    licenseId: str = Form(...),
    firm: str = Form(...),
    phone: str = Form(...),
    licenseImage: UploadFile = File(...)
):
    # Check if email exists
    if any(l["id"] == email for l in LAWYERS_DB):
        raise HTTPException(status_code=400, detail="Email already registered")
        
    # Validation: licenseImage must be an image
    if not licenseImage.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="License file must be an image")

    # Save License Image
    import shutil
    upload_dir = "uploads/licenses"
    os.makedirs(upload_dir, exist_ok=True)
    
    file_ext = os.path.splitext(licenseImage.filename)[1]
    filename = f"{email}_license{file_ext}"
    file_path = os.path.join(upload_dir, filename)
    
    try:
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(licenseImage.file, buffer)
    except Exception as e:
        print(f"Error saving license image: {e}")
        raise HTTPException(status_code=500, detail="Failed to save license image")
        
    # URL accessible via mounted /uploads path
    license_url = f"/uploads/licenses/{filename}"

    import uuid
    new_lawyer = {
        "id": email, # Use email as ID for simplicity
        "email": email, # Explicitly store email
        "name": name,
        "password": password, # Save password for mock auth
        "firm": firm,
        "location": "ì„œìš¸ (ë“±ë¡ ëŒ€ê¸°)",
        "career": f"ë³€í˜¸ì‚¬ ìê²©ì¦ ë²ˆí˜¸: {licenseId}",
        "education": "",
        "careerTags": ["ì‹ ê·œ"],
        "gender": "unknown",
        "expertise": ["ì¼ë°˜"],
        "matchScore": 0,
        "bestCase": {"title": "ë“±ë¡ ëŒ€ê¸° ì¤‘", "summary": "ì•„ì§ ë“±ë¡ëœ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤."},
        "imageUrl": "/static/images/default_avatar.png",
        "cutoutImageUrl": "/static/images/default_avatar.png",
        "bgRemoveStatus": "pending",
        "content_items": [],
        "content_highlights": "ì¸ì¦ ì‹¬ì‚¬ ì¤‘",
        "phone": phone,
        "homepage": None,
        "kakao_id": None,
        "verified": False, # New flag for verification
        "is_mock": False, # ì‹¤ì œ ê°€ì… ë³€í˜¸ì‚¬
        "licenseId": licenseId,
        "licenseImageUrl": license_url
    }

    # --- íŒŒìš´ë”© ë©¤ë²„ í˜œíƒ ìë™ ë¶€ì—¬ ---
    try:
        from billing import set_founder_benefits, set_standard_trial, FOUNDER_LIMIT  # type: ignore
    except ImportError:
        from billing import set_founder_benefits, set_standard_trial, FOUNDER_LIMIT  # type: ignore

    if len(LAWYERS_DB) < FOUNDER_LIMIT:
        set_founder_benefits(new_lawyer)
    else:
        set_standard_trial(new_lawyer)
    
    LAWYERS_DB.append(new_lawyer)
    save_lawyers_db(LAWYERS_DB)

    founder_msg = " ğŸš€ íŒŒìš´ë”© ë©¤ë²„ë¡œ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤! 3ê°œì›” ë¬´ë£Œ + í‰ìƒ 50% í• ì¸" if new_lawyer.get("is_founder") else ""
    return {"message": f"Signup successful{founder_msg}", "lawyer_id": new_lawyer["id"], "is_founder": new_lawyer.get("is_founder", False)}

class LawyerLoginRequest(BaseModel):
    email: str
    password: str

@app.post("/api/auth/login")
def login_lawyer(request: LawyerLoginRequest):
    # Find lawyer by email (id)
    lawyer = next((l for l in LAWYERS_DB if l["id"] == request.email), None)
    
    if not lawyer:
        raise HTTPException(status_code=400, detail="Invalid email or password")
    
    # Check password (simple verification for mock)
    # Note: Pre-filled mock data from data.py likely doesn't have 'password' field.
    # So we allow login for them if no password field exists (or handle it otherwise).
    # For new signups, we have the password.
    if "password" in lawyer and lawyer["password"] != request.password:
        raise HTTPException(status_code=400, detail="Invalid email or password")
        
    return {
        "message": "Login successful", 
        "lawyer": {
            "id": lawyer["id"],
            "name": lawyer["name"],
            "firm": lawyer["firm"],
            "verified": lawyer.get("verified", True) # Default true for old mocks
        }
    }

# --- Public Lawyer Profile API ---

@app.get("/api/public/lawyers")
def get_public_lawyers():
    """Get list of all lawyers (simplified) for sitemap/directory"""
    return [
        {
            "id": l["id"],
            "name": l["name"],
            "content_items": [
                {
                    "id": c["id"],
                    "slug": c.get("slug", c["id"]),
                    "date": c.get("date", ""),
                    "type": c.get("type", "blog")
                } for c in l.get("content_items", []) if c.get("verified")
            ]
        }
        for l in LAWYERS_DB
    ]

@app.get("/api/public/lawyers/{lawyer_id}")
def get_public_lawyer_detail(lawyer_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    # Return full details for public profile
    return {
        "id": lawyer["id"],
        "name": lawyer["name"],
        "firm": lawyer["firm"],
        "location": lawyer["location"],
        "career": lawyer["career"],
        "education": lawyer["education"],
        "expertise": lawyer["expertise"],
        "imageUrl": lawyer.get("imageUrl"),
        "cutoutImageUrl": lawyer.get("cutoutImageUrl"),
        "phone": lawyer.get("phone"),
        "homepage": lawyer.get("homepage"),
        "kakao_id": lawyer.get("kakao_id"),
        "introduction_short": lawyer.get("introduction_short"),
        "introduction_long": lawyer.get("introduction_long"),
        "content_items": [item for item in lawyer.get("content_items", []) if item.get("verified")],
        "cases": lawyer.get("cases", [])
    }

# --- Legal Magazine API ---

@app.get("/api/magazine")
def get_magazine_articles():
    import urllib.parse
    
    def generate_ai_image_url(prompt: str) -> str:
        """Generate a dynamic AI image URL using pollinations.ai"""
        # Ignore input prompt (which might be Korean/complex) and use safe presets
        import random
        safe_prompts = [
            "lawyer working at desk, professional, cinematic, 4k",
            "supreme court building, architecture, dramatic sky",
            "legal documents, pen, closeup, detailed",
            "judge gavel, wooden, blurred background, high quality",
            "statue of lady justice, silhouette, sunset"
        ]
        chosen_prompt = random.choice(safe_prompts)
        encoded = urllib.parse.quote(chosen_prompt)
        return f"https://image.pollinations.ai/prompt/{encoded}?width=800&height=600&nologo=true"

    # Gather all verified content from all lawyers
    articles = []
    
    # 1. From LAWYERS_DB (Verified content)
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            # Filter out admin injected content
            # Filter out admin injected content AND 'youtube' type (Score-only)
            if item.get("verified") and item.get("type") in ["column", "case"] and item.get("source") != "admin_injected":
                
                # Ensure cover image exists
                cover_image = item.get("image")
                if not cover_image and not item.get("file_url"):
                    # Generate one on the fly if missing (and persist it optionally, but here just return dynamic)
                    # For performance, we should persist, but for now let's just generate URL.
                    # Best to stick to what's in DB, but if DB is empty, provide dynamic one.
                    cover_image = generate_ai_image_url(item["title"])
                
                articles.append({
                    "id": item["id"],
                    "lawyer_id": lawyer["id"],  # type: ignore
                    "lawyer_name": lawyer["name"],  # type: ignore
                    "lawyer_firm": lawyer.get("firm", "Lawnald Partner"),
                    "lawyer_firm": lawyer.get("firm", "Lawnald Partner"),
                    "lawyer_image": lawyer.get("cutoutImageUrl") or lawyer.get("imageUrl"), # Frontend handles null with default icon
                    "type": item["type"],
                    "type": item["type"],
                    "title": item["title"],
                    "summary": item.get("content", "")[:100] + "..." if item.get("content") else f"{item['title']}ì— ëŒ€í•œ ë²•ë¥ ì  ë¶„ì„ê³¼ í•´ê²° ì‚¬ë¡€ì…ë‹ˆë‹¤.",
                    "content": item.get("content", ""), # Return full content
                    "date": item.get("date") or item.get("timestamp", "")[:10] or "2025-01-01",
                    "tags": item.get("topic_tags", []),
                    "url": item.get("url"),
                    "cover_image": cover_image
                })
                
    # Sort by date desc initially to prioritize latest when deduplicating
    articles.sort(key=lambda x: x["date"] or "", reverse=True)
    
    # 2. Deduplicate by standardized title
    unique_articles = []
    seen_titles = set()
    
    import re
    def normalize_title(t):
        # Remove extensions, special chars, standardize
        t = re.sub(r'\.(pdf|docx|txt)$', '', t, flags=re.IGNORECASE)
        t = re.sub(r'[_\-]', ' ', t)
        return t.strip()

    # Deterministic helpers for enrichment (simulate "analysis")
    def get_mock_enrichment(output_id):
        # deterministically generate based on ID hash
        h = sum(ord(c) for c in output_id)
        
        durations = ["3ê°œì›”", "6ê°œì›”", "8ê°œì›”", "1ë…„", "1ë…„ 4ê°œì›”", "2ë…„"]
        results = [
            "ìŠ¹ì†Œ (ì „ë¶€ ìŠ¹ì†Œ)", "ì¼ë¶€ ìŠ¹ì†Œ (80% ì¸ì •)", "í™”í•´ ê¶Œê³  ê²°ì •", 
            "ì¡°ì • ì„±ë¦½", "ì§‘í–‰ìœ ì˜ˆ", "ê¸°ì†Œìœ ì˜ˆ", "ë¬´ì£„ íŒê²°"
        ]
        issues_pool = [
            "ì¦ê±° ë¶ˆì¶©ë¶„ ì…ì¦", "ë²•ë¦¬ì  ì˜¤í•´ ì£¼ì¥", "ì ˆì°¨ì  ìœ„ë²•ì„± ê°•ì¡°", 
            "í”¼í•´ì í•©ì˜ ìœ ë„", "ì–‘í˜• ì‚¬ìœ  ì ê·¹ ì†Œëª…", "ì¬ì‚° í˜•ì„± ê¸°ì—¬ë„ ì…ì¦",
            "ê³„ì•½ í•´ì„ì˜ ë‹¤íˆ¼", "ê³¼ì‹¤ ë¹„ìœ¨ ì‚°ì •"
        ]
        
        return {
            "duration": durations[h % len(durations)],
            "result": results[(h + 1) % len(results)],
            "key_issues": [
                issues_pool[(h + 2) % len(issues_pool)],
                issues_pool[(h + 5) % len(issues_pool)]
            ]
        }

    for art in articles:
        norm_title = normalize_title(art["title"])
        
        # Humanize title for display
        art["display_title"] = norm_title
        
        if norm_title in seen_titles:
            continue
            
        seen_titles.add(norm_title)
        
        # Enrich if missing
        # Check if item has 'case_result' usually not in content_items of old mocks
        # So we use mock generator
        enrichment = get_mock_enrichment(art["id"])
        
        art["key_issues"] = art.get("key_issues") or enrichment["key_issues"]
        art["result_summary"] = art.get("result_summary") or enrichment["result"]
        art["duration"] = art.get("duration") or enrichment["duration"]
        
        # Simplify category mapping
        type_map = {"case": "ìŠ¹ì†Œì‚¬ë¡€", "column": "ë²•ë¥ ì¹¼ëŸ¼", "blog": "ë¸”ë¡œê·¸"}
        art["category_label"] = type_map.get(art["type"], "ê¸°íƒ€")
        
        unique_articles.append(art)
        
    return unique_articles

@app.get("/api/magazine/{article_id}")
def get_magazine_article_detail(article_id: str):
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item["id"] == article_id:
                # Found the item
                return {
                    "id": item["id"],
                    "lawyer_id": lawyer["id"],  # type: ignore
                    "lawyer_name": lawyer["name"],  # type: ignore
                    "lawyer_image": lawyer.get("cutoutImageUrl"),
                    "firm": lawyer.get("firm", "Lawnald Partner"),
                    "type": item["type"],
                    "title": item["title"],
                    "summary": item.get("summary") or (item.get("content", "")[:100] + "..." if item.get("content") else f"{item['title']}ì— ëŒ€í•œ ìš”ì•½ì…ë‹ˆë‹¤."),
                    "content": item.get("content") or f"{item['title']}ì— ëŒ€í•œ ìƒì„¸ ë‚´ìš©ì…ë‹ˆë‹¤.\n\n(ë³¸ë¬¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.)",
                    "date": item["date"],
                    "tags": item.get("topic_tags", []),
                    "url": item.get("url")
                }
    
    raise HTTPException(status_code=404, detail="ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")





# --- Content Submission ---

class ContentSubmission(BaseModel):
    type: str # column, youtube, book, lecture
    title: str
    content: Optional[str] = None # Text content or Description
    url: Optional[str] = None
    tags: List[str] = []

def generate_youtube_summary(url: str, title: str) -> str:
    # Deprecated: User requested Score-Only system.
    # No summary generation, just return empty or placeholder.
    return ""

@app.post("/api/lawyers/{lawyer_id}/content")
def submit_general_content(lawyer_id: str, submission: ContentSubmission):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    # Process YouTube
    summary = ""
    content_body = submission.content or ""
    
    if submission.type == "youtube":
        if not submission.url:
             raise HTTPException(status_code=400, detail="YouTube URL is required")
        # Auto-summarize
        summary = generate_youtube_summary(submission.url, submission.title)  # type: ignore
        # Append summary to content body if empty, or just use it
        if not content_body:
            content_body = summary
    else:
        # Default summary
        summary = content_body[:100] + "..." if content_body else ""  # type: ignore
        
    # (Prior logic for YouTube summary or default summary remains above)

        
    # --- Content Validation ---
    # 1. Length Check
    len_check = content_validator.validate_length(content_body, min_length=100) # relaxed for manual testing  # type: ignore
    if not len_check["valid"]:
        raise HTTPException(status_code=400, detail=len_check["message"])

    # 2. Keyword Density (Extract from title first)
    target_keywords = seo.seo_generator.extract_keywords(submission.title)
    kw_check = content_validator.check_keyword_density(content_body, target_keywords)  # type: ignore
    if not kw_check["valid"]:
        # Warning only, don't block
        print(f"Content Warning: {kw_check['warnings']}")

    # 3. Duplicate Check (using async wrapper needed? No, just call synchronous part if possible or await)
    # Since search_engine is synchronous mostly, let's just run it. 
    # But validator is async def... let's fix validator to be sync for simplicity in this prototype
    # or just await it if we are in async def. 
    # THIS FUNCTION IS 'def' not 'async def'. 
    # Let's assume validation is fast enough or use sync version.
    
    # --- PII Masking ---
    content_body = seo.pii_masker.mask(content_body)
    submission.title = seo.pii_masker.mask(submission.title)

    # --- SEO Generation ---
    slug = seo.seo_generator.generate_slug(submission.title)
    seo_title = seo.seo_generator.generate_seo_title(submission.title, lawyer["name"], submission.type)
    meta_desc = seo.seo_generator.generate_meta_description(content_body, summary)
    
    # Store SEO data
    seo_data = {
        "slug": slug,
        "seo_title": seo_title,
        "meta_description": meta_desc,
        "robots": "index, follow",
        "canonical": f"https://lawnald.com/magazine/{slug}",
        "faq": seo.seo_generator.generate_faq(content_body, submission.title),
        "schema_org": "{}" # Generated at runtime or stored here. Let's rely on runtime generation in frontend or generate now.
    }
        
    # --- Auto Image Generation ---
    image_url = None
    if submission.url and isinstance(submission.url, str) and submission.url.startswith("http"):  # type: ignore
        if "jpg" in submission.url or "png" in submission.url:  # type: ignore
            image_url = submission.url
            
    if not image_url:
        import urllib.parse
        import random
        # Use safe, English-only prompts with random variation to ensure stability
        safe_prompts = [
            "legal concept, cinematic lighting, professional, 4k",
            "modern law firm office, interior design, cinematic",
            "courtroom, gavel, justice, dramatic lighting",
            "law books, library, wisdom, professional",
            "scales of justice, golden hour, cinematic"
        ]
        chosen_prompt = random.choice(safe_prompts)
        encoded = urllib.parse.quote(chosen_prompt)
        image_url = f"https://image.pollinations.ai/prompt/{encoded}?width=800&height=600&nologo=true"

    import uuid
    new_submission = {
        "id": str(uuid.uuid4()),
        "lawyer_id": lawyer_id,
        "lawyer_name": lawyer["name"],
        "type": submission.type,
        "title": submission.title,
        "summary": summary,
        "content": content_body,
        "topic_tags": submission.tags,
        "status": "approved", # Auto-approve for demo convenience
        "date": datetime.now().strftime("%Y-%m-%d"),
        "url": submission.url,
        "image": image_url, # Save the generated image
        "seo": seo_data
    }
    
    # Direct add to lawyer items for demo speed
    lawyer["content_items"].insert(0, new_submission)
    save_db()
    
    return {"message": "ì½˜í…ì¸ ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.", "item": new_submission}

@app.get("/api/lawyers/{lawyer_id}/cases")
def get_lawyer_cases(lawyer_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
        
    # distinct from cases.py, this returns the 'content_items' of type 'case'
    cases = [item for item in lawyer.get("content_items", []) if item.get("type") == "case"]
    cases.sort(key=lambda x: x.get("date", ""), reverse=True)
    return cases

@app.delete("/api/lawyers/{lawyer_id}/content/{item_id}")
def delete_lawyer_content(lawyer_id: str, item_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    content_items = lawyer.get("content_items", [])
    initial_len = len(content_items)
    
    # Filter out the item to delete
    lawyer["content_items"] = [item for item in content_items if item.get("id") != item_id]
    
    if len(lawyer["content_items"]) == initial_len:
        raise HTTPException(status_code=404, detail="Content not found")
        
    save_lawyers_db(LAWYERS_DB)
    return {"message": "Content deleted successfully"}

@app.get("/api/admin/lawyers/pending", response_model=List[LawyerModel])
def get_pending_lawyers():
    # ì‹¤ì œ ê°€ì… ë³€í˜¸ì‚¬ ì¤‘ ë¯¸ì¸ì¦ëœ ë³€í˜¸ì‚¬ë§Œ ë°˜í™˜ (ê°€ìƒ ë³€í˜¸ì‚¬ ì œì™¸)
    return [l for l in LAWYERS_DB if l.get("verified") is False and not l.get("is_mock", False)]

@app.post("/api/admin/lawyers/{lawyer_id}/verify")
def verify_lawyer(lawyer_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="ë³€í˜¸ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    lawyer["verified"] = True
    lawyer["location"] = lawyer["location"].replace(" (ë“±ë¡ ëŒ€ê¸°)", "") # Remove pending tag if present
    lawyer["matchScore"] = 50 # Give a base score so they can appear in search
    lawyer["content_highlights"] = "ì‹ ê·œ ë“±ë¡ ë³€í˜¸ì‚¬"
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": "ë³€í˜¸ì‚¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.", "lawyer": lawyer}

# --- Admin Lawyer Management (List & Edit) ---

class LawyerUpdateModel(BaseModel):
    name: Optional[str] = None
    firm: Optional[str] = None
    location: Optional[str] = None
    career: Optional[str] = None
    education: Optional[str] = None
    phone: Optional[str] = None
    homepage: Optional[str] = None
    kakao_id: Optional[str] = None
    expertise: Optional[List[str]] = None
    introduction_short: Optional[str] = None
    introduction_long: Optional[str] = None

@app.get("/api/admin/lawyers", response_model=List[LawyerModel])
def get_all_lawyers(q: Optional[str] = None, include_mock: bool = False):
    filtered = LAWYERS_DB if include_mock else [l for l in LAWYERS_DB if not l.get("is_mock", False)]
    if q:
        return [l for l in filtered if q.lower() in l["name"].lower() or q.lower() in l["id"].lower()]
    return filtered

@app.put("/api/admin/lawyers/{lawyer_id}")
def update_lawyer(lawyer_id: str, update_data: LawyerUpdateModel):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="ë³€í˜¸ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Update fields if provided
    if update_data.name is not None: lawyer["name"] = update_data.name
    if update_data.firm is not None: lawyer["firm"] = update_data.firm
    if update_data.location is not None: lawyer["location"] = update_data.location
    if update_data.career is not None: lawyer["career"] = update_data.career
    if update_data.education is not None: lawyer["education"] = update_data.education
    if update_data.phone is not None: lawyer["phone"] = update_data.phone
    if update_data.homepage is not None: lawyer["homepage"] = update_data.homepage
    if update_data.kakao_id is not None: lawyer["kakao_id"] = update_data.kakao_id
    if update_data.expertise is not None: lawyer["expertise"] = update_data.expertise
    if update_data.introduction_short is not None: lawyer["introduction_short"] = update_data.introduction_short
    if update_data.introduction_long is not None: lawyer["introduction_long"] = update_data.introduction_long
    
    print(f"Updated lawyer {lawyer_id}: {update_data}")
    save_lawyers_db(LAWYERS_DB)
    return {"message": "ë³€í˜¸ì‚¬ ì •ë³´ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "lawyer": lawyer}



# --- Real-time Chat System ---


@app.get("/api/lawyers/{lawyer_id}/chats")
def get_lawyer_chats(lawyer_id: str):
    return chat_manager.get_lawyer_chats(lawyer_id)

@app.get("/api/chats/{lawyer_id}/{client_id}/messages")
def get_chat_history(lawyer_id: str, client_id: str):
    return chat_manager.get_history(lawyer_id, client_id)

# --- Analytics API ---

class BlogMetrics(BaseModel):
    views: int = 0
    dwell_time_avg: float = 0.0 # seconds
    clicks: int = 0 # CTA clicks
    conversions: int = 0 # Chat/Call checks

# In-memory metrics storage (lawyer_id -> {slug -> BlogMetrics})
# For prototype, we store in a simple dict.
BLOG_METRICS_DB: Dict[str, Dict[str, BlogMetrics]] = {}

@app.post("/api/analytics/track")
def track_analytics(
    lawyer_id: str = Body(...),
    slug: str = Body(...),
    event_type: str = Body(..., regex="^(view|click|conversion|dwell)$"),
    value: float = Body(0.0)
):
    if lawyer_id not in BLOG_METRICS_DB:
        BLOG_METRICS_DB[lawyer_id] = {}
    
    if slug not in BLOG_METRICS_DB[lawyer_id]:
        BLOG_METRICS_DB[lawyer_id][slug] = BlogMetrics()
        
    metrics = BLOG_METRICS_DB[lawyer_id][slug]
    
    if event_type == "view":
        metrics.views += 1
    elif event_type == "click":
        metrics.clicks += 1
    elif event_type == "conversion":
        metrics.conversions += 1
    elif event_type == "dwell":
        # simple moving average for prototype
        current_total = metrics.dwell_time_avg * metrics.views # approx
        metrics.dwell_time_avg = (current_total + value) / max(1, metrics.views)
        
    return {"status": "ok"}

@app.get("/api/lawyers/{lawyer_id}/analytics")
def get_lawyer_analytics(lawyer_id: str):
    if lawyer_id not in BLOG_METRICS_DB:
        return {"total_views": 0, "top_posts": []}
    
    data = BLOG_METRICS_DB[lawyer_id]
    total_views = sum(m.views for m in data.values())
    total_conversions = sum(m.conversions for m in data.values())
    
    top_posts = []
    for slug, metrics in data.items():
        top_posts.append({
            "slug": slug,
            "views": metrics.views,
            "clicks": metrics.clicks,
            "dwell_time": round(metrics.dwell_time_avg, 1)  # type: ignore
        })
    
    top_posts.sort(key=lambda x: x["views"], reverse=True)
    
    return {
        "total_views": total_views,
        "total_conversions": total_conversions,
        "avg_dwell_time": sum(m.dwell_time_avg for m in data.values()) / max(1, len(data)) if data else 0,
        "top_posts": top_posts[:5]  # type: ignore
    }


# --- Case Upload & Parsing ---
try:
    from case_parser_v2 import case_parser  # type: ignore
    print("DEBUG: Successfully imported case_parser from case_parser_v2")
except ImportError as e:
    print(f"DEBUG: Failed to import case_parser_v2: {e}")
    try:
        from case_parser_v2 import case_parser  # type: ignore
        print("DEBUG: Successfully imported case_parser from case_parser_v2")
    except ImportError as e2:  # type: ignore
        print(f"DEBUG: Failed to import case_parser_v2: {e2}")
        # Re-raise to see the error in logs if both fail
        raise e2


try:
    from seo import seo_generator  # type: ignore
except ImportError:
    from seo import seo_generator  # type: ignore

class CasePublishRequest(BaseModel):
    case_number: str
    court: str
    title: str
    story: str # The 1000-char narrative
    full_text: str
    lawyer_id: str
    file_hash: str
    ai_tags: str = ""
    summary: str = "" # Short summary/excerpt
    facts: str = "" # Added to match endpoint usage
    emotional_title: Optional[str] = None # New field
    emotional_summary: Optional[str] = None # New field
    key_takeaways: Optional[List[str]] = [] # New field for checklists




@app.post("/api/cases/upload")
async def upload_case_pdf(file: UploadFile = File(...)):
    # 1. Validate file type
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Only PDF files are allowed.")
    
    # 2. Save temporarily
    temp_dir = "temp_uploads"
    os.makedirs(temp_dir, exist_ok=True)
    temp_path = os.path.join(temp_dir, f"{uuid4()}_{file.filename}")
    
    try:
        with open(temp_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        abs_temp_path = os.path.abspath(temp_path)
        print(f"DEBUG: Endpoint uploaded file to: {abs_temp_path}")

        # 3. Extract Text
        raw_text = case_parser.extract_text_from_pdf(temp_path)
        text_len = len(raw_text.strip()) if raw_text else 0
        print(f"DEBUG: Extracted text length: {text_len}")
        
        # Calculate File Hash for Deduplication
        with open(temp_path, "rb") as f:
            file_bytes = f.read()
            file_hash = hashlib.sha256(file_bytes).hexdigest()

        # Deduplication Check: Look across all lawyers
        for lawyer in LAWYERS_DB:
            for item in lawyer.get("content_items", []):
                if item.get("file_hash") == file_hash:
                    case_parser.log_debug(f"DEBUG: Duplicate PDF detected (Hash: {file_hash[:10]}...)")  # type: ignore
                    raise HTTPException(status_code=409, detail="ì´ë¯¸ ë“±ë¡ëœ íŒê²°ë¬¸ì…ë‹ˆë‹¤. ì¤‘ë³µ ì—…ë¡œë“œëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # Check if text is sufficient. If not, try Vision fallback
        if not raw_text or text_len < 100:
             print("DEBUG: Text extraction insufficient (<100 chars). Attempting Vision Parsing (OCR Fallback)...")
             structured_data = case_parser.parse_from_images(temp_path)
        else:
             structured_data = case_parser.parse_structure(raw_text)
        
        # 5. Anonymize (First pass)
        structured_data["full_text"] = case_parser.anonymize_additional(structured_data["full_text"])
        
        structured_data["file_hash"] = file_hash
        
        case_parser.log_debug(f"DEBUG: upload_case_pdf returning narrative. Story len: {len(structured_data.get('client_story', ''))}")
        return structured_data

    except Exception as e:
        import traceback
        print(f"CRITICAL ERROR in upload_case_pdf: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # Cleanup
        if os.path.exists(temp_path):
            os.remove(temp_path)

@app.post("/api/cases/publish")
async def publish_case(data: CasePublishRequest):
    """
    Submit a winning case for admin approval.
    """
    lawyer = next((l for l in LAWYERS_DB if l["id"] == data.lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found.")

    # Deduplication Check (Final)
    for existing_item in lawyer.get("content_items", []):
        if existing_item.get("file_hash") == data.file_hash:
            raise HTTPException(status_code=409, detail="ì´ë¯¸ ë“±ë¡ëœ íŒê²°ë¬¸ì…ë‹ˆë‹¤.")

    # 1. Create Pending Item
    case_id = str(uuid4())
    print(f"DEBUG: Generated case_id={case_id}")

    slug = seo_generator.generate_slug(data.title)
    
    pending_item = {
        "id": case_id,
        "type": "case",
        "title": data.title,
        "summary": data.summary or data.story[:100] + "...",  # type: ignore
        "content": data.story, # The full narrative
        "full_text": data.full_text, # Original text (anonymized)
        "case_number": data.case_number,
        "court": data.court,
        "topic_tags": [t.strip() for t in data.ai_tags.split(",") if t.strip()],
        "file_hash": data.file_hash,
        "status": "pending", # Awaiting admin approval
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "date": datetime.now().strftime("%Y-%m-%d"), # Required for magazine feed
        "slug": slug,
        "lawyer_id": data.lawyer_id,
        "lawyer_name": lawyer["name"],
        "key_takeaways": data.key_takeaways or [] # Persist key takeaways
    }
    
    if "content_items" not in lawyer:
        lawyer["content_items"] = []
    
    lawyer["content_items"].insert(0, pending_item)
    save_lawyers_db(LAWYERS_DB)
    
    # RAG: ì„ë² ë”© ì €ì¥
    try:
        from case_embeddings import store_case_embedding  # type: ignore
        store_case_embedding(
            case_id=case_id,
            lawyer_id=data.lawyer_id,
            lawyer_name=lawyer["name"],
            title=data.title,
            content=data.story,
            case_number=data.case_number,
            court=data.court,
            ai_tags=data.ai_tags,
            file_hash=data.file_hash
        )
    except Exception as e:
        print(f"âš ï¸ RAG ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    
    return {"message": "ìŠ¹ì†Œì‚¬ë¡€ê°€ ì„±ê³µì ìœ¼ë¡œ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ê²Œì‹œë©ë‹ˆë‹¤.", "case_id": case_id}


# --- Bulk Upload / Publish ---

@app.post("/api/cases/bulk-upload")
async def bulk_upload_pdfs(files: List[UploadFile] = File(...)):
    """
    ìµœëŒ€ 20ê°œ íŒê²°ë¬¸ PDFë¥¼ ì¼ê´„ ì—…ë¡œë“œí•˜ê³  AI ë¶„ì„.
    ê° íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if len(files) > 20:
        raise HTTPException(status_code=400, detail="ìµœëŒ€ 20ê°œ íŒŒì¼ê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    if len(files) == 0:
        raise HTTPException(status_code=400, detail="íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    results = []
    temp_dir = "temp_uploads"
    os.makedirs(temp_dir, exist_ok=True)
    
    for idx, file in enumerate(files):
        result = {
            "index": idx,
            "filename": file.filename,
            "status": "pending",
            "error": None,
            "data": None
        }
        
        if not file.filename.lower().endswith('.pdf'):
            result["status"] = "error"
            result["error"] = f"PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤: {file.filename}"
            results.append(result)
            continue
        
        temp_path = os.path.join(temp_dir, f"{uuid4()}_{file.filename}")
        
        try:
            # Save temp file
            with open(temp_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            # Extract text
            raw_text = case_parser.extract_text_from_pdf(temp_path)
            text_len = len(raw_text.strip()) if raw_text else 0
            
            # File hash for dedup
            with open(temp_path, "rb") as f:
                file_bytes = f.read()
                file_hash = hashlib.sha256(file_bytes).hexdigest()
            
            # Dedup check
            is_duplicate = False
            for lawyer in LAWYERS_DB:
                for item in lawyer.get("content_items", []):
                    if item.get("file_hash") == file_hash:
                        is_duplicate = True
                        break
                if is_duplicate:
                    break
            
            if is_duplicate:
                result["status"] = "duplicate"
                result["error"] = "ì´ë¯¸ ë“±ë¡ëœ íŒê²°ë¬¸ì…ë‹ˆë‹¤."
                results.append(result)
                continue
            
            # Parse with AI
            if not raw_text or text_len < 100:
                structured_data = case_parser.parse_from_images(temp_path)
            else:
                structured_data = case_parser.parse_structure(raw_text)
            
            # Anonymize full text
            structured_data["full_text"] = case_parser.anonymize_additional(structured_data["full_text"])
            structured_data["file_hash"] = file_hash
            
            result["status"] = "success"
            result["data"] = structured_data
            
        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)
        
        results.append(result)
    
    success_count = sum(1 for r in results if r["status"] == "success")
    error_count = sum(1 for r in results if r["status"] == "error")
    duplicate_count = sum(1 for r in results if r["status"] == "duplicate")
    warning_count = sum(1 for r in results if r["status"] == "success" and r["data"] and r["data"].get("has_name_warning"))
    
    return {
        "total": len(files),
        "success": success_count,
        "errors": error_count,
        "duplicates": duplicate_count,
        "name_warnings": warning_count,
        "results": results
    }


class BulkPublishItem(BaseModel):
    case_number: str = ""
    court: str = ""
    title: str
    story: str  # client_story
    full_text: str = ""
    file_hash: str
    ai_tags: str = ""
    summary: str = ""
    key_takeaways: Optional[List[str]] = []

class BulkPublishRequest(BaseModel):
    lawyer_id: str
    cases: List[BulkPublishItem]

@app.post("/api/cases/bulk-publish")
async def bulk_publish_cases(data: BulkPublishRequest):
    """
    ì—¬ëŸ¬ ê±´ì˜ ìŠ¹ì†Œì‚¬ë¡€ë¥¼ ì¼ê´„ ê²Œì‹œ ìš”ì²­.
    """
    lawyer = next((l for l in LAWYERS_DB if l["id"] == data.lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found.")
    
    if "content_items" not in lawyer:
        lawyer["content_items"] = []
    
    published = []
    skipped = []
    
    for case_item in data.cases:
        # Dedup check
        is_dup = any(
            item.get("file_hash") == case_item.file_hash
            for item in lawyer.get("content_items", [])
        )
        if is_dup:
            skipped.append({"title": case_item.title, "reason": "ì¤‘ë³µ"})
            continue
        
        case_id = str(uuid4())
        slug = seo_generator.generate_slug(case_item.title)
        
        pending_item = {
            "id": case_id,
            "type": "case",
            "title": case_item.title,
            "summary": case_item.summary or case_item.story[:100] + "...",
            "content": case_item.story,
            "full_text": case_item.full_text,
            "case_number": case_item.case_number,
            "court": case_item.court,
            "topic_tags": [t.strip() for t in case_item.ai_tags.split(",") if t.strip()],
            "file_hash": case_item.file_hash,
            "status": "pending",
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "date": datetime.now().strftime("%Y-%m-%d"),
            "slug": slug,
            "lawyer_id": data.lawyer_id,
            "lawyer_name": lawyer["name"],
            "key_takeaways": case_item.key_takeaways or []
        }
        
        lawyer["content_items"].insert(0, pending_item)
        published.append({"title": case_item.title, "case_id": case_id})
        
        # RAG: ì„ë² ë”© ì €ì¥
        try:
            from case_embeddings import store_case_embedding  # type: ignore
            store_case_embedding(
                case_id=case_id,
                lawyer_id=data.lawyer_id,
                lawyer_name=lawyer["name"],
                title=case_item.title,
                content=case_item.story,
                case_number=case_item.case_number,
                court=case_item.court,
                ai_tags=case_item.ai_tags,
                file_hash=case_item.file_hash
            )
        except Exception as e:
            print(f"âš ï¸ RAG ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    
    save_lawyers_db(LAWYERS_DB)
    
    return {
        "message": f"{len(published)}ê±´ì˜ ìŠ¹ì†Œì‚¬ë¡€ê°€ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "published": len(published),
        "skipped": len(skipped),
        "details": published,
        "skipped_details": skipped
    }


# --- RAG: ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰ ---

class SimilarCaseQuery(BaseModel):
    query: str
    top_k: int = 5
    threshold: float = 0.5

@app.post("/api/cases/search-similar")
async def search_similar_cases_api(data: SimilarCaseQuery):
    """
    ì‚¬ê±´ê°œìš”ë¥¼ ì…ë ¥í•˜ë©´ ìœ ì‚¬ íŒë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ë²¡í„° ìœ ì‚¬ë„(ì½”ì‚¬ì¸) ê¸°ë°˜ ê²€ìƒ‰.
    """
    if not data.query.strip():
        raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    try:
        from case_embeddings import search_similar_cases  # type: ignore
        results = search_similar_cases(
            query=data.query,
            top_k=data.top_k,
            threshold=data.threshold
        )
        return {
            "query": data.query,
            "count": len(results),
            "results": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/cases/rag-setup")
async def get_rag_setup_sql():
    """RAG í…Œì´ë¸” ì„¤ì • SQLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        from case_embeddings import SETUP_SQL  # type: ignore
        return {"sql": SETUP_SQL}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/admin/drafts")
async def get_admin_drafts():
    """
    Get all pending winning cases for admin approval.
    """
    pending_items = []
    # print("DEBUG: fetching admin drafts...")
    for lawyer in LAWYERS_DB:
        # print(f"DEBUG: Checking lawyer {lawyer['id']}, items: {len(lawyer.get('content_items', []))}")
        for item in lawyer.get("content_items", []):
            if item.get("status") == "pending":
                # print(f"DEBUG: Found pending item: {item.get('title')}")
                pending_items.append(item)
    
    # print(f"DEBUG: Total pending items found: {len(pending_items)}")
    return sorted(pending_items, key=lambda x: x.get("timestamp", ""), reverse=True)



@app.get("/api/admin/submissions")
async def get_admin_submissions(status: str = "pending"):
    """
    Get all submissions for admin approval.
    """
    pending_items = []
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item.get("status") == status:
                # Add lawyer info to item for admin view if not present
                if "lawyer_name" not in item:
                    item["lawyer_name"] = lawyer["name"]  # type: ignore
                if "lawyer_id" not in item:
                    item["lawyer_id"] = lawyer["id"]  # type: ignore
                
                # Ensure topic_tags exists if tags exists
                if "topic_tags" not in item and "tags" in item:
                    item["topic_tags"] = item["tags"]
                    
                pending_items.append(item)
    
    return sorted(pending_items, key=lambda x: x.get("timestamp", ""), reverse=True)


@app.post("/api/admin/submissions/{item_id}/approve")
async def approve_submission(item_id: str):
    """
    Approve a submission by ID. Finds the lawyer and updates status.
    """
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item.get("id") == item_id:
                if item.get("status") == "published":
                    return {"message": "Already approved"}
                
                item["status"] = "published"
                item["verified"] = True
                
                # Boost score
                if "suitability_score" not in lawyer:
                    lawyer["suitability_score"] = 0
                lawyer["suitability_score"] += 10  # type: ignore
                
                save_lawyers_db(LAWYERS_DB)
                return {"message": "Approved successfully"}
                
    raise HTTPException(status_code=404, detail="Submission not found")


@app.post("/api/admin/submissions/{item_id}/reject")
async def reject_submission(item_id: str):
    """
    Reject a submission by ID.
    """
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item.get("id") == item_id:
                item["status"] = "rejected"
                save_lawyers_db(LAWYERS_DB)
                return {"message": "Rejected successfully"}
                
    raise HTTPException(status_code=404, detail="Submission not found")


@app.post("/api/admin/cases/approve")
async def approve_case(case_id: str = Body(...), lawyer_id: str = Body(...)):
    """
    Legacy Admin approval endpoint: publishes the case and boosts lawyer score.
    """
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found.")
        
    case_item = next((item for item in lawyer.get("content_items", []) if item.get("id") == case_id), None)
    if not case_item:
        raise HTTPException(status_code=404, detail="Case not found.")
        
    if case_item.get("status") == "published":
        return {"message": "ì´ë¯¸ ìŠ¹ì¸ëœ ì‚¬ë¡€ì…ë‹ˆë‹¤."}
        
    # 1. Update Status
    case_item["status"] = "published"
    case_item["verified"] = True # Critical for magazine visibility
    
    # 2. Boost Lawyer Suitability Score
    if "suitability_score" not in lawyer:
        lawyer["suitability_score"] = 0
    
    lawyer["suitability_score"] += 10 # Boost by 10 per approved case
    
    save_lawyers_db(LAWYERS_DB)
    
    return {
        "message": f"'{case_item['title']}' ì‚¬ë¡€ê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "new_score": lawyer["suitability_score"]
    }


# --- Consultation API ---
@app.post("/api/consultations")
async def create_consultation(request: ConsultationCreateRequest):
    """
    Creates a new consultation request and analyzes it with AI.
    """
    lawyer = next((l for l in LAWYERS_DB if l["id"] == request.lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")

    # Analyze with AI
    analysis = consultation.analyze_consultation_text(request.text)
    
    # Create Consultation Object
    new_consultation = {
        "id": str(uuid4()),
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "status": "new",
        "client_name": request.client_name or "ìµëª…",
        "client_phone": request.client_phone or "",
        "original_text": request.text,
        # AI Analysis Results
        "case_title": analysis.get("case_title", "ì œëª© ì—†ìŒ"),
        "primary_area": analysis.get("primary_area", "ê¸°íƒ€"),
        "summary": analysis.get("summary", ""),
        "confidence": analysis.get("confidence", 0.0),
        "key_facts": analysis.get("key_facts", []),
        "key_issues": analysis.get("key_issues", []),
        "checklist": analysis.get("checklist", []),
        "next_steps": analysis.get("next_steps", []),
        "risk_notes": analysis.get("risk_notes", []),
        "missing_questions": analysis.get("missing_questions", []),
        "tags": [analysis.get("primary_area", "ê¸°íƒ€")]
    }
    
    if "consultations" not in lawyer:
        lawyer["consultations"] = []
        
    lawyer["consultations"].insert(0, new_consultation)
    save_lawyers_db(LAWYERS_DB)
    
    return {"message": "Consultation created", "id": new_consultation["id"]}

@app.get("/api/consultations")
async def get_consultations(lawyer_id: str, status: Optional[str] = None, search: Optional[str] = None):
    """
    Get consultations for a specific lawyer, optionally filtered by status or search text.
    """
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
        
    consultations = lawyer.get("consultations", [])
    
    # Filter by status
    if status and status != "":
        consultations = [c for c in consultations if c.get("status") == status]
        
    # Filter by search query
    if search and search != "":
        search_lower = search.lower()
        consultations = [c for c in consultations if 
                         search_lower in c.get("case_title", "").lower() or 
                         search_lower in c.get("summary", "").lower() or
                         search_lower in c.get("client_name", "").lower()]
                         
    return consultations

# --- Case Archive API ---
try:
    from cases import case_manager  # type: ignore
except ImportError:
    from cases import case_manager  # type: ignore

@app.get("/api/cases/admin")
def get_admin_cases():
    return case_manager.get_all_cases_admin()

@app.get("/api/cases/my")
def get_my_cases(lawyer_id: str = "lawyer1@example.com"): # Hardcoded for now
    return case_manager.get_my_cases(lawyer_id)

@app.get("/api/cases/archive")
def get_archive_cases(query: Optional[str] = None, field: Optional[str] = None):
    return case_manager.get_archive_cases(query, field)

class CaseSubmission(BaseModel):
    title: str
    summary: str
    tags: List[str]
    case_type: str
    field: str
    result: str
    stage: str
    
    # Original Data
    client_name: str
    client_phone: str
    case_number: str
    judge_name: str
    full_text: str
    internal_notes: str

@app.post("/api/cases")
def submit_case(submission: CaseSubmission):
    lawyer_id = "lawyer1@example.com" # Mock auth
    return case_manager.submit_case(lawyer_id, submission.dict())

class StatusUpdate(BaseModel):
    status: str
    feedback: Optional[str] = None

@app.put("/api/cases/{case_id}/status")
def update_case_status(case_id: str, update: StatusUpdate):
    success = case_manager.update_status(case_id, update.status, update.feedback)
    if not success:
        raise HTTPException(status_code=404, detail="Case not found")
    return {"status": "success"}

# --- Magazine Management (Admin) ---

@app.post("/api/admin/content/{content_id}/toggle-visibility")
def toggle_content_visibility(content_id: str):
    """Toggle the 'verified' status of a content item."""
    for lawyer in LAWYERS_DB:
        for item in lawyer.get("content_items", []):
            if item["id"] == content_id:
                item["verified"] = not item.get("verified", False)
                save_db()
                return {"message": "Visibility toggled", "verified": item["verified"]}
    raise HTTPException(status_code=404, detail="Content not found")

@app.delete("/api/admin/content/{content_id}")
def delete_content(content_id: str):
    """Permanently delete a content item."""
    for lawyer in LAWYERS_DB:
        content_items = lawyer.get("content_items", [])
        for i, item in enumerate(content_items):
            if item["id"] == content_id:
                del content_items[i]
                save_db()
                return {"message": "Content deleted"}
    raise HTTPException(status_code=404, detail="Content not found")

# --- Admin Lawyer Management ---

class BatchLawyerIds(BaseModel):
    lawyer_ids: List[str]

class LawyerUpdateModel(BaseModel):
    name: Optional[str] = None
    firm: Optional[str] = None
    location: Optional[str] = None
    career: Optional[str] = None
    education: Optional[str] = None
    phone: Optional[str] = None
    homepage: Optional[str] = None
    kakao_id: Optional[str] = None
    expertise: Optional[List[str]] = None
    introduction_short: Optional[str] = None
    introduction_long: Optional[str] = None

@app.get("/api/admin/lawyers/pending")
def get_pending_lawyers():
    # ì‹¤ì œ ê°€ì… ë³€í˜¸ì‚¬ ì¤‘ ë¯¸ì¸ì¦ëœ ë³€í˜¸ì‚¬ë§Œ ë°˜í™˜ (ê°€ìƒ ë³€í˜¸ì‚¬ ì œì™¸)
    return [l for l in LAWYERS_DB if l.get("verified") is False and not l.get("is_mock", False)]

@app.post("/api/admin/lawyers/{lawyer_id}/verify")
def verify_lawyer(lawyer_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="ë³€í˜¸ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    lawyer["verified"] = True
    lawyer["location"] = lawyer["location"].replace(" (ë“±ë¡ ëŒ€ê¸°)", "")
    lawyer["matchScore"] = 50
    lawyer["content_highlights"] = "ì‹ ê·œ ë“±ë¡ ë³€í˜¸ì‚¬"
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": "ë³€í˜¸ì‚¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.", "lawyer": lawyer}

@app.post("/api/admin/lawyers/{lawyer_id}/reject")
def reject_lawyer(lawyer_id: str):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="ë³€í˜¸ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    LAWYERS_DB.remove(lawyer)
    save_lawyers_db(LAWYERS_DB)
    return {"message": "ë³€í˜¸ì‚¬ ê°€ì…ì´ ë°˜ë ¤ë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.post("/api/admin/lawyers/batch-verify")
def batch_verify_lawyers(data: BatchLawyerIds):
    verified_count = 0
    for lawyer_id in data.lawyer_ids:
        lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
        if lawyer and lawyer.get("verified") is False:
            lawyer["verified"] = True
            lawyer["location"] = lawyer.get("location", "").replace(" (ë“±ë¡ ëŒ€ê¸°)", "")
            lawyer["matchScore"] = 50
            lawyer["content_highlights"] = "ì‹ ê·œ ë“±ë¡ ë³€í˜¸ì‚¬"
            verified_count += 1
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{verified_count}ëª…ì˜ ë³€í˜¸ì‚¬ê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "count": verified_count}

@app.post("/api/admin/lawyers/batch-reject")
def batch_reject_lawyers(data: BatchLawyerIds):
    rejected_count = 0
    to_remove = []
    for lawyer_id in data.lawyer_ids:
        lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
        if lawyer and lawyer.get("verified") is False:
            to_remove.append(lawyer)
            rejected_count += 1
    
    for lawyer in to_remove:
        LAWYERS_DB.remove(lawyer)
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": f"{rejected_count}ëª…ì˜ ë³€í˜¸ì‚¬ ê°€ì…ì´ ë°˜ë ¤ë˜ì—ˆìŠµë‹ˆë‹¤.", "count": rejected_count}

@app.get("/api/admin/lawyers")
def get_all_lawyers(q: Optional[str] = None, include_mock: bool = False):
    filtered = LAWYERS_DB if include_mock else [l for l in LAWYERS_DB if not l.get("is_mock", False)]
    if q:
        return [l for l in filtered if q.lower() in l["name"].lower() or q.lower() in l["id"].lower()]
    return filtered

@app.put("/api/admin/lawyers/{lawyer_id}")
def update_lawyer(lawyer_id: str, update_data: LawyerUpdateModel):
    lawyer = next((l for l in LAWYERS_DB if l["id"] == lawyer_id), None)
    if not lawyer:
        raise HTTPException(status_code=404, detail="Lawyer not found")
    
    update_dict = update_data.dict(exclude_unset=True)
    for key, value in update_dict.items():
        if value is not None:
            lawyer[key] = value
    
    save_lawyers_db(LAWYERS_DB)
    return {"message": "Updated", "lawyer": lawyer}
